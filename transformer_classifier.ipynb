{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el6WZUx3ctwE",
    "outputId": "f66a38ff-d81d-4b57-d8b2-a43989ee3151"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.utils.data as data_utils\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Bernoulli\n",
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math \n",
    "import torch\n",
    "from torch.nn.functional import softplus\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#!ls drive/'My Drive/YYY_deep_project_YYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUc-3FwsYA6X",
    "outputId": "0e1b95cc-1151-4102-ccea-a9e0edbe1f5d"
   },
   "outputs": [],
   "source": [
    "#%cd drive/'My Drive/YYY_deep_project_YYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OcYm_Z9sdVq4"
   },
   "outputs": [],
   "source": [
    "def get_sequence(infile):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        header = infile.readline()\n",
    "        sequence = infile.readline()\n",
    "\n",
    "        pdb = header[1:5]\n",
    "\n",
    "        if not header or not sequence or set(sequence) == {'X'}:\n",
    "            return\n",
    "        \n",
    "        yield header.strip()[1:], sequence.strip(), pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "mzJSiJbpXkTR",
    "outputId": "2af42cfb-ef10-4316-de19-6b89fa008527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences = []\n",
    "pdb_to_seq = {}\n",
    "count = 0\n",
    "with open('data/all_heavy.fasta') as infile:\n",
    "\n",
    "        for header, sequence, pdb in get_sequence(infile):\n",
    "            sequences.append(list(sequence))            \n",
    "            pdb_to_seq[pdb.lower()] = sequence\n",
    "            \n",
    "sequences = [seq for seq in sequences if len(seq) < 150]\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "mode = max(set(lengths), key=lengths.count)\n",
    "print(mode)\n",
    "\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6548\n",
      "1088 5460\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/sabdab_summary_all-2.tsv', sep='\\t')\n",
    "df = df[['pdb', 'affinity']]\n",
    "df['sequence'] = df['pdb'].map(pdb_to_seq)\n",
    "df = df.loc[~df['sequence'].isna()]\n",
    "df = df.loc[df['sequence'].str.strip('-').str.len() < 300]\n",
    "print(len(df))\n",
    "\n",
    "df['affinity'] = [float(aff) if aff != 'None' else np.NaN for aff in df['affinity']]\n",
    "labelled = df.dropna()\n",
    "unlabelled = df.loc[df['affinity'].isnull()]\n",
    "\n",
    "print(len(labelled), len(unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    948\n",
      "0    140\n",
      "Name: binder, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-bdf718d4123b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labelled['binder'] = (labelled.affinity < 500*10**(-9)).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# make binder column for labelled data\n",
    "labelled['binder'] = (labelled.affinity < 500*10**(-9)).astype(int)\n",
    "print(labelled.binder.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lVSriKBHdqU7"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve inputs and targets at the given index\n",
    "        X = self.inputs[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "def create_datasets(sequences, targets, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):\n",
    "    \n",
    "    # Define partition sizes\n",
    "    num_train = int(len(sequences)*p_train)\n",
    "    num_val = int(len(sequences)*p_val)\n",
    "    num_test = int(len(sequences)*p_test)\n",
    "\n",
    "    # Split sequences into partitions\n",
    "    sequences_train = sequences[:num_train-1]\n",
    "    targets_train = targets[:num_train-1]\n",
    "    \n",
    "    # add reversed sequences for training and shuffle\n",
    "    #sequences_train += [seq[::-1] for seq in sequences_train]\n",
    "    #shuffle(sequences_train)\n",
    "\n",
    "    sequences_val = sequences[num_train:num_train+num_val-1]\n",
    "    targets_val = targets[num_train:num_train+num_val-1]\n",
    "\n",
    "    sequences_test = sequences[-num_test:-1]\n",
    "    targets_test = targets[-num_test:-1]\n",
    "    \n",
    "    \n",
    "    input_train = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_train]\n",
    "    input_val = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_val]\n",
    "    input_test = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_test]\n",
    "\n",
    "\n",
    "    \n",
    "    return (input_train, targets_train), (input_val, targets_val), (input_test, targets_test)\n",
    "\n",
    "\n",
    "(input_train, targets_train), (input_val, targets_val), (input_test, targets_test) = create_datasets(labelled['sequence'].tolist(), labelled['binder'].tolist(), Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples for training: 869 869\n",
      "Samples for validation: 107 107\n",
      "Samples for testing: 107 107\n"
     ]
    }
   ],
   "source": [
    "print('Samples for training:', len(input_train), len(targets_train))\n",
    "print('Samples for validation:', len(input_val), len(targets_val))\n",
    "print('Samples for testing:', len(input_test), len(targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YNWaI923d3YE"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "        \n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.t_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "        self.embed = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        \n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.t_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "\n",
    "        # neuron per aa\n",
    "        self.ff = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        # \"classification layer\" - two neurons\n",
    "        self.ff_out = nn.Linear(ntoken, 2)\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float(-1e-10)).masked_fill(mask == 1, float(0.0))\n",
    "        \n",
    "        return mask\n",
    "\n",
    " \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "       \n",
    "\n",
    "    def forward(self, src, src_mask, tgt, tgt_mask, mem_pad_mask=None):\n",
    "        \n",
    "\n",
    "        embeds = self.embed(src) * math.sqrt(self.ninp)\n",
    "        \n",
    "        positions = self.pos_encoder(embeds)\n",
    "    \n",
    "        \n",
    "        encoded = self.t_encoder(positions)\n",
    "        #encoded = self.t_encoder(positions, src_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        \n",
    "        #if mem_pad_mask is None:\n",
    "        #    mem_pad_mask = tgt_pad_mask.clone()\n",
    "            \n",
    "        embeds = self.embed(tgt)\n",
    "        positions = self.pos_encoder(embeds)\n",
    "        #decoded = self.t_decoder(tgt=positions, memory=encoded, tgt_mask=tgt_mask,\n",
    "        #                         tgt_key_padding_mask=tgt_pad_mask,\n",
    "        #                         memory_key_padding_mask=mem_pad_mask)\n",
    "        \n",
    "        decoded = self.t_decoder(tgt=positions, memory=encoded, tgt_mask=tgt_mask)\n",
    "  \n",
    "        out = self.ff(decoded)\n",
    "        \n",
    "        output_class = F.softmax(self.ff_out(out),dim=1)\n",
    "\n",
    "        return output_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBtnWGt-Al99",
    "outputId": "50cdbe94-9ab1-4a92-a5e6-5f50335a9208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([869, 291]) torch.Size([869, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-5dd2d50bfb3a>:30: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tgt_tensor = torch.LongTensor(targets_one_hot)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "vocab = ['<pad>', \"<sos>\", \"<eos>\"] + [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"X\",\"Y\"]\n",
    "char_nums = {token:vocab.index(token) for token in vocab}\n",
    "\n",
    "def one_hot_encode(idx, num_classes):\n",
    "    # Initialize the encoded array\n",
    "    one_hot = np.zeros(num_classes)\n",
    "    \n",
    "    # Set the appropriate element to one\n",
    "    one_hot[idx] = 1.0\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def batchify(sources, targets, max_len):\n",
    "\n",
    "    # convert to respective aa ids\n",
    "    sources_numeric = [[char_nums[char] for char in seq] for seq in sources]\n",
    "    \n",
    "    seq_lengths = torch.LongTensor([len(seq) for seq in sources])\n",
    "\n",
    "    # dump padding everywhere, and place seqs on the left.\n",
    "    # you need a tensor as big as your longest sequence\n",
    "    src_tensor = torch.zeros((len(sources_numeric), max_len)).long()\n",
    "    \n",
    "    for idx, (seq, seqlen) in enumerate(zip(sources_numeric, seq_lengths)):\n",
    "        src_tensor[idx, :(seqlen)] = torch.LongTensor(seq)\n",
    "    \n",
    "    # convert target to long tensor\n",
    "    targets_one_hot = [one_hot_encode(tgt,2) for tgt in targets]\n",
    "    tgt_tensor = torch.LongTensor(targets_one_hot)\n",
    "    \n",
    "    \n",
    "    # SORT YOUR TENSORS BY LENGTH!\n",
    "    #seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "    #src_tensor = src_tensor[perm_idx]\n",
    "    #tgt_tensor = tgt_tensor[perm_idx]\n",
    "\n",
    "    return src_tensor, tgt_tensor\n",
    "\n",
    "seq_lengths = torch.LongTensor([len(seq) for seq in labelled['sequence'].tolist()])\n",
    "max_len = seq_lengths.max() +2    # plus 2 for <sos> and <eos>\n",
    "\n",
    "(train_src, train_tgt) = batchify(input_train, targets_train, max_len)\n",
    "(val_src, val_tgt) = batchify(input_val, targets_val, max_len)\n",
    "(test_src, test_tgt) = batchify(input_test, targets_test, max_len)\n",
    "\n",
    "print(train_src.shape, train_tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "UglAQA33frSw"
   },
   "outputs": [],
   "source": [
    "bptt = 60\n",
    "\n",
    "def get_batch(sources, targets, i):\n",
    "    n_seqs_in_batch = min(bptt, len(sources) - 1 - i)\n",
    "    targets=targets.unsqueeze(1)\n",
    "    src = torch.cat([sources[i] for i in range(n_seqs_in_batch)]).view(n_seqs_in_batch, max_len)\n",
    "        \n",
    "    tgt = torch.cat([targets[i] for i in range(n_seqs_in_batch)])#.view(n_seqs_in_batch)#.reshape(-1)\n",
    "    \n",
    "    return src, tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 16, 20,  ...,  0,  0,  0],\n",
       "         [ 1,  6, 20,  ...,  0,  0,  0],\n",
       "         [ 1, 13,  8,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  6, 20,  ...,  0,  0,  0],\n",
       "         [ 1,  6, 20,  ...,  0,  0,  0],\n",
       "         [ 1,  6, 20,  ...,  0,  0,  0]]),\n",
       " tensor([[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(train_src, train_tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "tLXVBEIrfr-D"
   },
   "outputs": [],
   "source": [
    "ntokens = len(vocab) # the size of vocabulary\n",
    "emsize = 800 # embedding dimension\n",
    "nhid = 400 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.5 # the dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Qc1m7dgifuPc"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#  ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "lr = 4.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#optimizer  = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model.to(device)\n",
    "import sys\n",
    "import time\n",
    "def train():\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    n_batches = 0\n",
    "    \n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(vocab)\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_src.size(0) - 1, bptt)):\n",
    "        \n",
    "        data, targets = get_batch(train_src, train_tgt, i)\n",
    "    \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        #src_pad_mask = (data == 0).bool().view(data.size(1), data.size(0))\n",
    "        \n",
    "        tgt_mask = model.generate_square_subsequent_mask(targets.size(0)).to(device)\n",
    "        #tgt_pad_mask = (targets == 0).bool().view(targets.size(1), targets.size(0))\n",
    "        \n",
    "        output = model(data, src_mask, targets, tgt_mask)\n",
    "     \n",
    "        #output_trans = output.view(-1, ntokens)\n",
    "        #target_trans = targets.view(-1, targets.size(1) * targets.size(0)).squeeze(0) \n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        n_batches += 1\n",
    "        train_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        \n",
    "        # Soft, hard accuracy\n",
    "        #o = list(output.view(-1, ntokens)[0])\n",
    "        #t = targets\n",
    "        #print(o,t)\n",
    "        #hard_acc = sum([i for i in range(len(targets)) if o[i] == t[i]])/len(targets)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        log_interval = 1\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}|'.format(\n",
    "                    epoch, batch, len(train_src) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "    train_losses.append(train_loss/n_batches)\n",
    "\n",
    "def evaluate(eval_model, src, tgt):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    \n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, src.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(src, tgt, i)\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            #src_pad_mask = (data == 0).bool().view(data.size(1), data.size(0))\n",
    "        \n",
    "            tgt_mask = model.generate_square_subsequent_mask(targets.size(0)).to(device)\n",
    "            #tgt_pad_mask = (targets == 0).bool().view(targets.size(1), targets.size(0))    \n",
    "            \n",
    "            output = eval_model(data, src_mask, targets, tgt_mask)#, src_pad_mask, tgt_pad_mask)\n",
    "            \n",
    "            #output_trans = output.view(-1, ntokens)\n",
    "            #target_trans = targets.view(-1, targets.size(1) * targets.size(0)).squeeze(0)\n",
    "            \n",
    "            total_loss += len(data) * criterion(output, targets).item()\n",
    "            \n",
    "    return total_loss / (len(src) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "tZDramCJfwec",
    "outputId": "6b842e7f-b493-42a1-8118-c263cf475722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/   14 batches | lr 4.00 | ms/batch 68128.72 | loss  1.55 | ppl     4.73|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0d9c97193ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-85d85486e223>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#tgt_pad_mask = (targets == 0).bool().view(targets.size(1), targets.size(0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#output_trans = output.view(-1, ntokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-eaefe5bbc580>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, tgt, tgt_mask, mem_pad_mask)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m#encoded = self.t_encoder(positions, src_key_padding_mask=src_pad_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[1;32m    294\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[1;32m    977\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4316\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4317\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4318\u001b[0;31m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4319\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_src, val_tgt)\n",
    "    val_losses.append(val_loss)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XPTZdip9XkTT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.707452886045191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.707452886045191"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_losses[-1])\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDPz0G4MfyL6",
    "outputId": "b7e93030-f301-44ea-e6ba-5d917286e439"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-de4b76e565b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n\u001b[1;32m      4\u001b[0m     test_loss, math.exp(test_loss)))\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-8ab574967eda>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(eval_model, src, tgt)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mtgt_pad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0moutput_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-ce4dbee06f0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, tgt, tgt_mask, src_pad_mask, tgt_pad_mask, mem_pad_mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m#encoded = self.t_encoder(positions, src_key_padding_mask=src_pad_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[1;32m    294\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[1;32m    977\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4146\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_src, test_tgt)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZsUG0R1oXkTT"
   },
   "outputs": [],
   "source": [
    "idx_to_letter = {val:key for key, val in char_nums.items()}\n",
    "\n",
    "def sample_categorical(lnprobs, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample an element from a categorical distribution\n",
    "    :param lnprobs: Outcome log-probabilities\n",
    "    :param temperature: Sampling temperature. 1.0 follows the given distribution,\n",
    "        0.0 returns the maximum probability element.\n",
    "    :return: The index of the sampled element.\n",
    "    \"\"\"\n",
    "\n",
    "    if temperature == 0.0:\n",
    "        return lnprobs.argmax()\n",
    "    p = F.softmax(lnprobs / temperature, dim=1)\n",
    "\n",
    "    #print(\"softmaxed probs:\", p)\n",
    "    \n",
    "    return dist.Categorical(p).sample()\n",
    "\n",
    "def sample_sentence(model, query, max_len = 140, temperature=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    while len(query) < max_len and '<eos>' not in query:\n",
    "        query_tensor, seq_lengths = batchify([query])\n",
    "        query_tensor = query_tensor.to(device)\n",
    "    \n",
    "        src_mask = model.generate_square_subsequent_mask(len(query_tensor)).to(device)\n",
    "        \n",
    "        output = model(query_tensor, src_mask, torch.Tensor([len(query)])).view(-1, ntokens)\n",
    "        \n",
    "        next_char_idx = sample_categorical(output, temperature) #0.5\n",
    "                \n",
    "        try:\n",
    "            query += [idx_to_letter[int(next_char_idx[-1])]]\n",
    "        except IndexError:\n",
    "            query += [idx_to_letter[int(next_char_idx)]]\n",
    "            \n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3rHcGmkG3_m",
    "outputId": "45ef1fc7-ae43-48ac-dc0a-f5382bd3d713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 <sos> E P T F S S S G G T A S L V Y G L V T K G G S S G T W M M Y T A M N D Q M Y T C T A S S G G L V P D T P V T P A A K <eos>\n",
      "119 <sos> E V L V T T V T G Y F T Y G L V T V D T V T V T V L V T V T V T A R D T L K K G L V T T S S G L V S N S S G Q M M Y A R Q G L Q M S S L Q T V S S G T S G S A K L V T Y F A V A M Y W V T S S S G V S G T A S Y F A G T L V G E W L V K K <eos>\n",
      "500 <sos> E G Y W G T S S G G L V T T A V K R Q M Y Y Y F P G V K N E P V T V T Y W Q M Y Y F P S G D K N N S S E P V T V K I E W T F T V T S L V T V T Q M G G G Y Y G L V T L V S Q K G G L Q M Y F T F T V S T S G V T A G L V T Y P G L V T S G S G T W Y T A K G R Q K G G R D T S V N S S L V A K S G V T S T S L Q M Y F L V T Y T V T Y W V T S G G L V T V T H T W V Q M Y W V T P S G Q M N T V T T P S D N L Q T P S G T V F T V K G Q M S L V T T S Y F P G G G S G Y F T T T T P V T L V T L V T V S L V T A V T V H I L Q M Y F S S G S S T V R D T P P G Y W L V T V T L Q P V T N S V T S L V L Q M G T A R D T F T S G G I S S G Q H I S G L Y F T W D S S G Y W L Q M Y Y Y W G T V K G L S S V D A V T V T L Q M G Y P V T L Q M Y F T V Q M G G L S L V K R Q M Y P V K K K R Q M D A K R I S S L V G G P V T V T V T T K G V A T V T A S G L Q M S S S S G L V T S S G G Q M Y Y Y W V D S T F T M D T A S Y G P G E P A S S S G S S G G L V T V E W L V S L V T L V K G A V T S S G L V Y F T L S S T N S S S G G Q T Y N\n",
      "197 <sos> E E P K K P V V T V T S T A A M Y F T Y Y G L T Q M Y W G E D T V T A R D W S G G Y F A R D S S V T I S S S G Y T I S V T I L V T V T P S L V T Q N T S Y T A K K G Y W L V K G T V T L Q M Y W Y F T F L V T S L V T S S G L V T S S T N S S L V T A G L V T C A S S G S S L V Y W Y W V K G S T L Q M N T V T V T V T T A M Y F S G V T A A K K Y F L Q M Y W G G G G L V T S S S S S T K R D S Y H <eos>\n",
      "320 <sos> E V T L Q S G T W L S G T P S Y W T V V V T A K G P P V T Y Y C A G G G A S Y W N S G G G Y W L V T S S S S Y Y F S S S E T T N S S G Y W L Q M S N Y Y F T V T L S L V T S S L V Y G G Y L V T I E E D Y N T Y F T A G Y P V T S L Q M Y A R D A G L S G G G L V L Q M Y W M Y G K R D G L V K G G L V T A T V D T A S S V T S G C K R Q T V T P T F S T P V S L Q M Y Y Y F T F S Y F T V T A K L V T S D S V T Y W L S G Y T V T A S G Y W M S S S V K P S S G L Q M Y F T L L V Y F T L S S G Y T T L V T V T V T V T G V T A K G T V P P V T V T L S T S S S T L Q M G G L Q G D F A T V T L Q M D S G Y W V T V T L S G K G G G S G I E P A S S G L K <eos>\n",
      "500 <sos> E E W S E D G V T V T V T V K K L V T A V Y W S S L V T R D S L V P A K P G T L Q K S L V T V V T P L V T I E P A K G Y F T K G V L V K P V T Y F A T A T V T S S G Y W V T P D T L V T Q M Y F T Q P S T S Y F T V T L V K R D T V T Y F P T W G G G Y T G D S L E P P V T K K K K P S S G G Y P G R Q G G T V T T L A G L V K G L Q M Y Y A A A M S V T A V K G K G Y F S E P A A K G T V Y T Y Y F S L S L V T A T V S S T T G G L V T L V T V T V D T M Y P V Y Y T V T A G L S L S L Q M D Y F T F P S S T A V T V T Y G D F L V P P L Q T F T V S S L Q G L Q M Y W L V T A R I E D S G L S G L V T A S G F T S T F S S S L V V T S G L Q M S S L V S V T S L V S S T S L V T Q M G L V S T G G M G T S G G G L V T T Q M Y W G V T S S L V K T L Q M Y Y F T M Y P A T T S G F K K S T S V T V T I E D S L V T N V D N T T T A G C A K G G T P V T S S L V T Q M Y A S S V V T F T V T P V D S S S S Y Y W V T L Q M Y T Y W L R Q P P S G N N S L V T V T T F T V D G L S V T Y G Y W V K N T L S L L V Y F T P P A A G T A K\n",
      "16 <sos> E P G G G V S L Q M G L Q K <eos>\n",
      "28 <sos> E D G L V V Y F T C K K P P P P A R D D S L V K K R <eos>\n",
      "48 <sos> E P S G S G L V T A S S E W V W F T Q M Y T P S S L K L S S C R A R Q M Y P P V T V T A V K <eos>\n",
      "251 <sos> E P P P S G S V T I L S G Y Y T S V T S T S S S S L V K R Q M S T S D S T K N S S V S G C L V T V T V T V T A S V T V V L Q Q M M S G C A M D S L V T V T P G T F T P P D L Q M Y Y Y G S V D P L V T P P D A Q K G L V A R D T S G T L V T L V T V T V K N S G V A S S S S Y F S C A S L V T N A T V T P P T T P T P K G G G G G V T L V K G T L V K R Q M Y F T P V T S S L L K L K R Q M Y P P A V T P V T F S S Y F P D S L V K R D S S S G C A S S G L V K L Q M Y Y F T V T V T Y W F T V T T I E W L V V K <eos>\n"
     ]
    }
   ],
   "source": [
    "import torch.distributions as dist\n",
    "ntokens = len(vocab)\n",
    "\n",
    "for _ in range(10):\n",
    "    sample = sample_sentence(model, [\"<sos>\",\"E\"], max_len = 500, temperature=0.9)\n",
    "\n",
    "    print(len(sample), \" \".join(sample))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvvgjJGWHhB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d0EO5DHXkTT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project2_jonas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
