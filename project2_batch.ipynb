{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el6WZUx3ctwE",
    "outputId": "f66a38ff-d81d-4b57-d8b2-a43989ee3151"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\\n!ls drive/'My Drive/YYY_deep_project_YYY'\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls drive/'My Drive/YYY_deep_project_YYY'\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUc-3FwsYA6X",
    "outputId": "0e1b95cc-1151-4102-ccea-a9e0edbe1f5d"
   },
   "outputs": [],
   "source": [
    "#%cd drive/'My Drive/YYY_deep_project_YYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OcYm_Z9sdVq4"
   },
   "outputs": [],
   "source": [
    "def get_sequence(infile):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        header = infile.readline()\n",
    "        sequence = infile.readline()\n",
    "\n",
    "        pdb = header[1:5]\n",
    "\n",
    "        if not header or not sequence or set(sequence) == {'X'}:\n",
    "            return\n",
    "        \n",
    "        yield header.strip()[1:], sequence.strip(), pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "mzJSiJbpXkTR",
    "outputId": "2af42cfb-ef10-4316-de19-6b89fa008527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences = []\n",
    "seq_to_pdb = {}\n",
    "count = 0\n",
    "with open('all_heavy.fasta') as infile:\n",
    "\n",
    "        for header, sequence, pdb in get_sequence(infile):\n",
    "            #if count < 500:\n",
    "            sequences.append(list(sequence))\n",
    "                #count += 1\n",
    "            \n",
    "            seq_to_pdb[sequence] = pdb\n",
    "            \n",
    "sequences = [seq for seq in sequences if len(seq) < 200]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "mode = max(set(lengths), key=lengths.count)\n",
    "\n",
    "print(mode)\n",
    "\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()\n",
    "#sequences = [seq for seq in sequences if len(seq) == mode]\n",
    "\n",
    "# Take only shorter sequences to make it more quick\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lVSriKBHdqU7"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve inputs and targets at the given index\n",
    "        X = self.inputs[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "def create_datasets(sequences, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):\n",
    "    \n",
    "    \n",
    "    # Define partition sizes\n",
    "    num_train = int(len(sequences)*p_train)\n",
    "    num_val = int(len(sequences)*p_val)\n",
    "    num_test = int(len(sequences)*p_test)\n",
    "\n",
    "    # Split sequences into partitions\n",
    "    sequences_train = sequences[:num_train-1]\n",
    "    sequences_val = sequences[num_train:num_train+num_val-1]\n",
    "    sequences_test = sequences[-num_test:-1]\n",
    "\n",
    "    input_train = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_train]\n",
    "    input_val = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_val]\n",
    "    input_test = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_test]\n",
    "\n",
    "    return (input_train, input_val, input_test)\n",
    "\n",
    "(input_train, input_val, input_test) = create_datasets(sequences, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "YNWaI923d3YE"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "        \n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "        self.embed = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        \n",
    "        self.ff = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        \n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embed.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.ff.bias.data.zero_()\n",
    "        self.ff.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        #self.transformer_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask, seq_lengths):\n",
    "        \n",
    "        # utils.rnn lets you give (B,L,D) tensors where B is the batch size, L is the maxlength, if you use batch_first=True\n",
    "        # Otherwise, give (L,B,D) tensors\n",
    "        #seq_tensor = src.transpose(0,1) # (B,L,D) -> (L,B,D)\n",
    "        \n",
    "        seq_tensor = src\n",
    "        # embed your sequences\n",
    "        seq_tensor = self.embed(seq_tensor) * math.sqrt(self.ninp)\n",
    "        \n",
    "        # pack them up nicely\n",
    "        #packed_input = pack_padded_sequence(seq_tensor, seq_lengths.numpy())\n",
    "        \n",
    "        src = self.pos_encoder(seq_tensor)\n",
    "        \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "\n",
    "        output = self.transformer_decoder(output, src_mask)\n",
    "        #output = self.ff(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "q4ia5HMZfemk"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBtnWGt-Al99",
    "outputId": "50cdbe94-9ab1-4a92-a5e6-5f50335a9208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 18,  8,  ..., 15, 17,  2],\n",
       "        [ 1,  6, 20,  ...,  0,  0,  0],\n",
       "        [ 1, 16, 20,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1, 18,  8,  ...,  0,  0,  0],\n",
       "        [ 1, 18,  8,  ...,  0,  0,  0],\n",
       "        [ 1, 18, 13,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    \n",
    "vocab = ['<pad>', \"<sos>\", \"<eos>\"] + [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"X\",\"Y\"]\n",
    "char_nums = {token:vocab.index(token) for token in vocab}\n",
    "\n",
    "def batchify(data):\n",
    "    \n",
    "    # get the length of each seq in your batch\n",
    "    seq_lengths = torch.LongTensor([len(seq) for seq in data])\n",
    "\n",
    "    train_vectorized = [[char_nums[char] for char in seq] for seq in data]\n",
    "    \n",
    "    # dump padding everywhere, and place seqs on the left.\n",
    "    # NOTE: you only need a tensor as big as your longest sequence\n",
    "    seq_tensor = torch.zeros((len(train_vectorized), seq_lengths.max())).long()\n",
    "    for idx, (seq, seqlen) in enumerate(zip(train_vectorized, seq_lengths)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    # SORT YOUR TENSORS BY LENGTH!\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "\n",
    "    return seq_tensor, seq_lengths\n",
    "\n",
    "\n",
    "train_data, train_lengths = batchify(input_train)\n",
    "val_data, val_lengths = batchify(input_train)\n",
    "test_data, test_lengths = batchify(input_train)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "UglAQA33frSw"
   },
   "outputs": [],
   "source": [
    "bptt = 60\n",
    "max_len = max(map(len, sequences))\n",
    "def get_batch(source, i):\n",
    "    n_seqs = min(bptt, len(source) - 1 - i)\n",
    "    data = torch.cat([train_data[i][:-1] for i in range(n_seqs)]).view(n_seqs,max_len+1)\n",
    "    \n",
    "    target = torch.cat([train_data[i][1:] for i in range(n_seqs)]).view(n_seqs,max_len+1).reshape(-1)\n",
    "    \n",
    "    return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "tLXVBEIrfr-D"
   },
   "outputs": [],
   "source": [
    "ntokens = len(vocab) # the size of vocabulary\n",
    "emsize = 800 # embedding dimension\n",
    "nhid = 400 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.5 # the dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Qc1m7dgifuPc"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#  ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 4.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#optimizer  = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model.to(device)\n",
    "import sys\n",
    "import time\n",
    "def train():\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    n_batches = 0\n",
    "    \n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(vocab)\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        \n",
    "        data, targets = get_batch(train_data, i)\n",
    "    \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != bptt:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        \n",
    "        output = model(data, src_mask, train_lengths)\n",
    "        \n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        \n",
    "        n_batches += 1\n",
    "        train_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        \n",
    "        # Soft, hard accuracy\n",
    "        #o = list(output.view(-1, ntokens)[0])\n",
    "        #t = targets\n",
    "        #print(o,t)\n",
    "        #hard_acc = sum([i for i in range(len(targets)) if o[i] == t[i]])/len(targets)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        log_interval = 1\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}|'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "    train_losses.append(train_loss/n_batches)\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    \n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            \n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask, val_lengths)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "            \n",
    "    return total_loss / (len(data_source) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-2d1e82f6ad9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-0b43638d7bb4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, src_mask, seq_lengths)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m#output = self.ff(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[0;32m    232\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n\u001b[0m\u001b[0;32m    368\u001b[0m                                    key_padding_mask=memory_key_padding_mask)[0]\n\u001b[0;32m    369\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m    977\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_b\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m                     \u001b[0m_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4172\u001b[1;33m                 \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4174\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "data, targets = get_batch(train_data, 0)\n",
    "data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "\n",
    "out = model(data, src_mask, train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "tZDramCJfwec",
    "outputId": "6b842e7f-b493-42a1-8118-c263cf475722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/    9 batches | lr 4.00 | ms/batch 582.12 | loss 18.54 | ppl 112142794.21|\n",
      "| epoch   1 |     2/    9 batches | lr 4.00 | ms/batch 293.06 | loss 11.68 | ppl 118098.64|\n",
      "| epoch   1 |     3/    9 batches | lr 4.00 | ms/batch 287.07 | loss  6.45 | ppl   631.84|\n",
      "| epoch   1 |     4/    9 batches | lr 4.00 | ms/batch 287.07 | loss 10.83 | ppl 50410.81|\n",
      "| epoch   1 |     5/    9 batches | lr 4.00 | ms/batch 289.07 | loss  8.99 | ppl  8053.32|\n",
      "| epoch   1 |     6/    9 batches | lr 4.00 | ms/batch 289.07 | loss  8.01 | ppl  3016.19|\n",
      "| epoch   1 |     7/    9 batches | lr 4.00 | ms/batch 287.06 | loss  6.20 | ppl   492.72|\n",
      "| epoch   1 |     8/    9 batches | lr 4.00 | ms/batch 289.07 | loss  7.77 | ppl  2358.47|\n",
      "| epoch   1 |     9/    9 batches | lr 4.00 | ms/batch 122.02 | loss 14.62 | ppl 2231860.75|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  3.64s | valid loss 19.61 | valid ppl 328883532.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     1/    9 batches | lr 3.61 | ms/batch 579.14 | loss 25.50 | ppl 119149511813.20|\n",
      "| epoch   2 |     2/    9 batches | lr 3.61 | ms/batch 288.07 | loss  8.81 | ppl  6724.69|\n",
      "| epoch   2 |     3/    9 batches | lr 3.61 | ms/batch 287.06 | loss 10.06 | ppl 23475.98|\n",
      "| epoch   2 |     4/    9 batches | lr 3.61 | ms/batch 292.06 | loss  8.67 | ppl  5814.94|\n",
      "| epoch   2 |     5/    9 batches | lr 3.61 | ms/batch 291.07 | loss  8.02 | ppl  3048.60|\n",
      "| epoch   2 |     6/    9 batches | lr 3.61 | ms/batch 290.07 | loss  6.70 | ppl   809.72|\n",
      "| epoch   2 |     7/    9 batches | lr 3.61 | ms/batch 290.06 | loss  8.21 | ppl  3668.89|\n",
      "| epoch   2 |     8/    9 batches | lr 3.61 | ms/batch 290.07 | loss  6.31 | ppl   552.44|\n",
      "| epoch   2 |     9/    9 batches | lr 3.61 | ms/batch 122.02 | loss  9.61 | ppl 14924.35|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  3.64s | valid loss 11.71 | valid ppl 121619.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |     1/    9 batches | lr 3.43 | ms/batch 580.14 | loss 16.67 | ppl 17323506.29|\n",
      "| epoch   3 |     2/    9 batches | lr 3.43 | ms/batch 288.07 | loss  9.33 | ppl 11232.31|\n",
      "| epoch   3 |     3/    9 batches | lr 3.43 | ms/batch 290.07 | loss  9.46 | ppl 12880.41|\n",
      "| epoch   3 |     4/    9 batches | lr 3.43 | ms/batch 290.06 | loss  7.73 | ppl  2278.33|\n",
      "| epoch   3 |     5/    9 batches | lr 3.43 | ms/batch 286.07 | loss  9.02 | ppl  8256.75|\n",
      "| epoch   3 |     6/    9 batches | lr 3.43 | ms/batch 290.07 | loss  8.17 | ppl  3536.21|\n",
      "| epoch   3 |     7/    9 batches | lr 3.43 | ms/batch 289.06 | loss  7.86 | ppl  2600.47|\n",
      "| epoch   3 |     8/    9 batches | lr 3.43 | ms/batch 290.07 | loss  6.96 | ppl  1055.84|\n",
      "| epoch   3 |     9/    9 batches | lr 3.43 | ms/batch 120.02 | loss  6.27 | ppl   527.62|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  3.64s | valid loss  8.96 | valid ppl  7782.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |     1/    9 batches | lr 3.26 | ms/batch 582.13 | loss 11.79 | ppl 131982.02|\n",
      "| epoch   4 |     2/    9 batches | lr 3.26 | ms/batch 287.07 | loss  6.14 | ppl   464.54|\n",
      "| epoch   4 |     3/    9 batches | lr 3.26 | ms/batch 287.07 | loss  4.95 | ppl   140.80|\n",
      "| epoch   4 |     4/    9 batches | lr 3.26 | ms/batch 293.07 | loss  4.66 | ppl   105.35|\n",
      "| epoch   4 |     5/    9 batches | lr 3.26 | ms/batch 292.07 | loss  4.51 | ppl    90.93|\n",
      "| epoch   4 |     6/    9 batches | lr 3.26 | ms/batch 292.07 | loss  4.34 | ppl    76.78|\n",
      "| epoch   4 |     7/    9 batches | lr 3.26 | ms/batch 289.07 | loss  5.36 | ppl   213.51|\n",
      "| epoch   4 |     8/    9 batches | lr 3.26 | ms/batch 292.07 | loss  3.91 | ppl    49.67|\n",
      "| epoch   4 |     9/    9 batches | lr 3.26 | ms/batch 126.02 | loss  4.41 | ppl    81.89|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  3.68s | valid loss  5.48 | valid ppl   240.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |     1/    9 batches | lr 3.10 | ms/batch 580.69 | loss  8.45 | ppl  4681.56|\n",
      "| epoch   5 |     2/    9 batches | lr 3.10 | ms/batch 290.07 | loss  5.39 | ppl   219.55|\n",
      "| epoch   5 |     3/    9 batches | lr 3.10 | ms/batch 291.07 | loss  4.77 | ppl   118.01|\n",
      "| epoch   5 |     4/    9 batches | lr 3.10 | ms/batch 289.06 | loss  4.46 | ppl    86.83|\n",
      "| epoch   5 |     5/    9 batches | lr 3.10 | ms/batch 290.07 | loss  5.10 | ppl   164.18|\n",
      "| epoch   5 |     6/    9 batches | lr 3.10 | ms/batch 289.06 | loss  3.09 | ppl    21.95|\n",
      "| epoch   5 |     7/    9 batches | lr 3.10 | ms/batch 288.07 | loss  3.36 | ppl    28.85|\n",
      "| epoch   5 |     8/    9 batches | lr 3.10 | ms/batch 293.06 | loss  5.35 | ppl   211.09|\n",
      "| epoch   5 |     9/    9 batches | lr 3.10 | ms/batch 122.03 | loss  5.71 | ppl   300.52|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  3.67s | valid loss  6.67 | valid ppl   790.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |     1/    9 batches | lr 2.94 | ms/batch 592.15 | loss  7.91 | ppl  2728.61|\n",
      "| epoch   6 |     2/    9 batches | lr 2.94 | ms/batch 294.91 | loss  4.15 | ppl    63.23|\n",
      "| epoch   6 |     3/    9 batches | lr 2.94 | ms/batch 295.07 | loss  3.60 | ppl    36.75|\n",
      "| epoch   6 |     4/    9 batches | lr 2.94 | ms/batch 297.88 | loss  3.50 | ppl    33.17|\n",
      "| epoch   6 |     5/    9 batches | lr 2.94 | ms/batch 297.07 | loss  4.05 | ppl    57.13|\n",
      "| epoch   6 |     6/    9 batches | lr 2.94 | ms/batch 296.14 | loss 12.84 | ppl 375936.08|\n",
      "| epoch   6 |     7/    9 batches | lr 2.94 | ms/batch 294.60 | loss  6.23 | ppl   507.23|\n",
      "| epoch   6 |     8/    9 batches | lr 2.94 | ms/batch 294.99 | loss  2.74 | ppl    15.52|\n",
      "| epoch   6 |     9/    9 batches | lr 2.94 | ms/batch 122.99 | loss  6.03 | ppl   414.30|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  3.72s | valid loss  5.54 | valid ppl   255.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |     1/    9 batches | lr 2.79 | ms/batch 585.00 | loss  7.48 | ppl  1776.66|\n",
      "| epoch   7 |     2/    9 batches | lr 2.79 | ms/batch 287.01 | loss  2.77 | ppl    15.91|\n",
      "| epoch   7 |     3/    9 batches | lr 2.79 | ms/batch 291.99 | loss  3.86 | ppl    47.38|\n",
      "| epoch   7 |     4/    9 batches | lr 2.79 | ms/batch 298.01 | loss  2.31 | ppl    10.12|\n",
      "| epoch   7 |     5/    9 batches | lr 2.79 | ms/batch 296.00 | loss  2.68 | ppl    14.53|\n",
      "| epoch   7 |     6/    9 batches | lr 2.79 | ms/batch 295.95 | loss  2.72 | ppl    15.24|\n",
      "| epoch   7 |     7/    9 batches | lr 2.79 | ms/batch 296.04 | loss  2.69 | ppl    14.68|\n",
      "| epoch   7 |     8/    9 batches | lr 2.79 | ms/batch 291.98 | loss  2.77 | ppl    16.00|\n",
      "| epoch   7 |     9/    9 batches | lr 2.79 | ms/batch 125.23 | loss  3.16 | ppl    23.55|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  3.71s | valid loss  3.02 | valid ppl    20.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |     1/    9 batches | lr 2.65 | ms/batch 577.14 | loss  5.61 | ppl   274.23|\n",
      "| epoch   8 |     2/    9 batches | lr 2.65 | ms/batch 288.06 | loss  2.55 | ppl    12.85|\n",
      "| epoch   8 |     3/    9 batches | lr 2.65 | ms/batch 289.07 | loss  2.63 | ppl    13.85|\n",
      "| epoch   8 |     4/    9 batches | lr 2.65 | ms/batch 288.07 | loss  2.60 | ppl    13.42|\n",
      "| epoch   8 |     5/    9 batches | lr 2.65 | ms/batch 288.07 | loss  2.71 | ppl    15.00|\n",
      "| epoch   8 |     6/    9 batches | lr 2.65 | ms/batch 287.07 | loss  2.39 | ppl    10.88|\n",
      "| epoch   8 |     7/    9 batches | lr 2.65 | ms/batch 288.06 | loss  2.77 | ppl    16.00|\n",
      "| epoch   8 |     8/    9 batches | lr 2.65 | ms/batch 288.07 | loss  2.48 | ppl    11.94|\n",
      "| epoch   8 |     9/    9 batches | lr 2.65 | ms/batch 121.02 | loss  2.98 | ppl    19.71|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  3.63s | valid loss  2.35 | valid ppl    10.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |     1/    9 batches | lr 2.52 | ms/batch 577.14 | loss  5.25 | ppl   191.09|\n",
      "| epoch   9 |     2/    9 batches | lr 2.52 | ms/batch 288.07 | loss  2.51 | ppl    12.33|\n",
      "| epoch   9 |     3/    9 batches | lr 2.52 | ms/batch 290.07 | loss  2.26 | ppl     9.61|\n",
      "| epoch   9 |     4/    9 batches | lr 2.52 | ms/batch 293.07 | loss  2.29 | ppl     9.86|\n",
      "| epoch   9 |     5/    9 batches | lr 2.52 | ms/batch 292.06 | loss  2.12 | ppl     8.36|\n",
      "| epoch   9 |     6/    9 batches | lr 2.52 | ms/batch 291.07 | loss  2.60 | ppl    13.44|\n",
      "| epoch   9 |     7/    9 batches | lr 2.52 | ms/batch 292.07 | loss  2.19 | ppl     8.95|\n",
      "| epoch   9 |     8/    9 batches | lr 2.52 | ms/batch 289.07 | loss  2.27 | ppl     9.67|\n",
      "| epoch   9 |     9/    9 batches | lr 2.52 | ms/batch 121.02 | loss  2.80 | ppl    16.48|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  3.65s | valid loss  2.46 | valid ppl    11.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |     1/    9 batches | lr 2.39 | ms/batch 576.13 | loss  4.44 | ppl    85.07|\n",
      "| epoch  10 |     2/    9 batches | lr 2.39 | ms/batch 291.07 | loss  2.31 | ppl    10.12|\n",
      "| epoch  10 |     3/    9 batches | lr 2.39 | ms/batch 287.07 | loss  2.05 | ppl     7.74|\n",
      "| epoch  10 |     4/    9 batches | lr 2.39 | ms/batch 288.06 | loss  2.26 | ppl     9.55|\n",
      "| epoch  10 |     5/    9 batches | lr 2.39 | ms/batch 290.07 | loss  2.10 | ppl     8.17|\n",
      "| epoch  10 |     6/    9 batches | lr 2.39 | ms/batch 289.07 | loss  2.12 | ppl     8.34|\n",
      "| epoch  10 |     7/    9 batches | lr 2.39 | ms/batch 287.06 | loss  2.11 | ppl     8.26|\n",
      "| epoch  10 |     8/    9 batches | lr 2.39 | ms/batch 289.07 | loss  2.21 | ppl     9.09|\n",
      "| epoch  10 |     9/    9 batches | lr 2.39 | ms/batch 121.03 | loss  2.39 | ppl    10.95|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  3.64s | valid loss  2.28 | valid ppl     9.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |     1/    9 batches | lr 2.28 | ms/batch 581.13 | loss  4.16 | ppl    64.10|\n",
      "| epoch  11 |     2/    9 batches | lr 2.28 | ms/batch 290.06 | loss  2.10 | ppl     8.14|\n",
      "| epoch  11 |     3/    9 batches | lr 2.28 | ms/batch 288.06 | loss  2.07 | ppl     7.94|\n",
      "| epoch  11 |     4/    9 batches | lr 2.28 | ms/batch 289.06 | loss  2.05 | ppl     7.79|\n",
      "| epoch  11 |     5/    9 batches | lr 2.28 | ms/batch 289.07 | loss  2.09 | ppl     8.09|\n",
      "| epoch  11 |     6/    9 batches | lr 2.28 | ms/batch 289.07 | loss  2.17 | ppl     8.72|\n",
      "| epoch  11 |     7/    9 batches | lr 2.28 | ms/batch 290.07 | loss  1.93 | ppl     6.90|\n",
      "| epoch  11 |     8/    9 batches | lr 2.28 | ms/batch 289.06 | loss  2.13 | ppl     8.39|\n",
      "| epoch  11 |     9/    9 batches | lr 2.28 | ms/batch 122.03 | loss  2.19 | ppl     8.94|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  3.65s | valid loss  2.13 | valid ppl     8.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |     1/    9 batches | lr 2.16 | ms/batch 586.14 | loss  3.92 | ppl    50.36|\n",
      "| epoch  12 |     2/    9 batches | lr 2.16 | ms/batch 296.69 | loss  2.14 | ppl     8.50|\n",
      "| epoch  12 |     3/    9 batches | lr 2.16 | ms/batch 294.07 | loss  1.98 | ppl     7.24|\n",
      "| epoch  12 |     4/    9 batches | lr 2.16 | ms/batch 290.07 | loss  2.00 | ppl     7.39|\n",
      "| epoch  12 |     5/    9 batches | lr 2.16 | ms/batch 287.06 | loss  2.01 | ppl     7.46|\n",
      "| epoch  12 |     6/    9 batches | lr 2.16 | ms/batch 289.07 | loss  1.93 | ppl     6.91|\n",
      "| epoch  12 |     7/    9 batches | lr 2.16 | ms/batch 289.07 | loss  2.03 | ppl     7.65|\n",
      "| epoch  12 |     8/    9 batches | lr 2.16 | ms/batch 289.07 | loss  1.87 | ppl     6.49|\n",
      "| epoch  12 |     9/    9 batches | lr 2.16 | ms/batch 120.02 | loss  2.26 | ppl     9.58|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  3.66s | valid loss  1.88 | valid ppl     6.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |     1/    9 batches | lr 2.05 | ms/batch 580.13 | loss  3.86 | ppl    47.39|\n",
      "| epoch  13 |     2/    9 batches | lr 2.05 | ms/batch 289.07 | loss  1.89 | ppl     6.63|\n",
      "| epoch  13 |     3/    9 batches | lr 2.05 | ms/batch 290.07 | loss  1.88 | ppl     6.53|\n",
      "| epoch  13 |     4/    9 batches | lr 2.05 | ms/batch 289.07 | loss  1.90 | ppl     6.67|\n",
      "| epoch  13 |     5/    9 batches | lr 2.05 | ms/batch 289.06 | loss  1.85 | ppl     6.39|\n",
      "| epoch  13 |     6/    9 batches | lr 2.05 | ms/batch 288.07 | loss  1.88 | ppl     6.53|\n",
      "| epoch  13 |     7/    9 batches | lr 2.05 | ms/batch 288.07 | loss  1.90 | ppl     6.68|\n",
      "| epoch  13 |     8/    9 batches | lr 2.05 | ms/batch 291.07 | loss  1.84 | ppl     6.32|\n",
      "| epoch  13 |     9/    9 batches | lr 2.05 | ms/batch 122.03 | loss  2.17 | ppl     8.76|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  3.64s | valid loss  1.76 | valid ppl     5.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |     1/    9 batches | lr 1.95 | ms/batch 579.13 | loss  3.67 | ppl    39.39|\n",
      "| epoch  14 |     2/    9 batches | lr 1.95 | ms/batch 288.07 | loss  1.84 | ppl     6.28|\n",
      "| epoch  14 |     3/    9 batches | lr 1.95 | ms/batch 287.07 | loss  1.81 | ppl     6.12|\n",
      "| epoch  14 |     4/    9 batches | lr 1.95 | ms/batch 289.07 | loss  1.83 | ppl     6.26|\n",
      "| epoch  14 |     5/    9 batches | lr 1.95 | ms/batch 291.07 | loss  1.86 | ppl     6.42|\n",
      "| epoch  14 |     6/    9 batches | lr 1.95 | ms/batch 296.07 | loss  1.77 | ppl     5.90|\n",
      "| epoch  14 |     7/    9 batches | lr 1.95 | ms/batch 298.07 | loss  1.83 | ppl     6.25|\n",
      "| epoch  14 |     8/    9 batches | lr 1.95 | ms/batch 293.07 | loss  1.78 | ppl     5.94|\n",
      "| epoch  14 |     9/    9 batches | lr 1.95 | ms/batch 125.03 | loss  2.11 | ppl     8.27|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  3.70s | valid loss  1.74 | valid ppl     5.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |     1/    9 batches | lr 1.85 | ms/batch 584.13 | loss  3.50 | ppl    33.07|\n",
      "| epoch  15 |     2/    9 batches | lr 1.85 | ms/batch 292.07 | loss  1.82 | ppl     6.16|\n",
      "| epoch  15 |     3/    9 batches | lr 1.85 | ms/batch 289.07 | loss  1.82 | ppl     6.19|\n",
      "| epoch  15 |     4/    9 batches | lr 1.85 | ms/batch 291.07 | loss  1.77 | ppl     5.88|\n",
      "| epoch  15 |     5/    9 batches | lr 1.85 | ms/batch 293.07 | loss  1.77 | ppl     5.86|\n",
      "| epoch  15 |     6/    9 batches | lr 1.85 | ms/batch 292.06 | loss  1.78 | ppl     5.96|\n",
      "| epoch  15 |     7/    9 batches | lr 1.85 | ms/batch 289.07 | loss  1.79 | ppl     5.98|\n",
      "| epoch  15 |     8/    9 batches | lr 1.85 | ms/batch 288.07 | loss  1.73 | ppl     5.64|\n",
      "| epoch  15 |     9/    9 batches | lr 1.85 | ms/batch 123.03 | loss  2.05 | ppl     7.77|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  3.67s | valid loss  1.62 | valid ppl     5.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |     1/    9 batches | lr 1.76 | ms/batch 599.14 | loss  3.40 | ppl    29.83|\n",
      "| epoch  16 |     2/    9 batches | lr 1.76 | ms/batch 298.06 | loss  1.72 | ppl     5.58|\n",
      "| epoch  16 |     3/    9 batches | lr 1.76 | ms/batch 296.08 | loss  1.73 | ppl     5.61|\n",
      "| epoch  16 |     4/    9 batches | lr 1.76 | ms/batch 295.06 | loss  1.70 | ppl     5.47|\n",
      "| epoch  16 |     5/    9 batches | lr 1.76 | ms/batch 292.08 | loss  1.72 | ppl     5.58|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  16 |     6/    9 batches | lr 1.76 | ms/batch 296.06 | loss  1.70 | ppl     5.46|\n",
      "| epoch  16 |     7/    9 batches | lr 1.76 | ms/batch 292.07 | loss  1.75 | ppl     5.74|\n",
      "| epoch  16 |     8/    9 batches | lr 1.76 | ms/batch 290.07 | loss  1.69 | ppl     5.43|\n",
      "| epoch  16 |     9/    9 batches | lr 1.76 | ms/batch 122.02 | loss  2.02 | ppl     7.55|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  3.73s | valid loss  1.55 | valid ppl     4.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |     1/    9 batches | lr 1.67 | ms/batch 604.15 | loss  3.31 | ppl    27.45|\n",
      "| epoch  17 |     2/    9 batches | lr 1.67 | ms/batch 301.07 | loss  1.68 | ppl     5.35|\n",
      "| epoch  17 |     3/    9 batches | lr 1.67 | ms/batch 301.07 | loss  1.68 | ppl     5.37|\n",
      "| epoch  17 |     4/    9 batches | lr 1.67 | ms/batch 298.07 | loss  1.68 | ppl     5.34|\n",
      "| epoch  17 |     5/    9 batches | lr 1.67 | ms/batch 299.07 | loss  1.66 | ppl     5.29|\n",
      "| epoch  17 |     6/    9 batches | lr 1.67 | ms/batch 299.07 | loss  1.67 | ppl     5.33|\n",
      "| epoch  17 |     7/    9 batches | lr 1.67 | ms/batch 300.07 | loss  1.69 | ppl     5.41|\n",
      "| epoch  17 |     8/    9 batches | lr 1.67 | ms/batch 301.07 | loss  1.65 | ppl     5.20|\n",
      "| epoch  17 |     9/    9 batches | lr 1.67 | ms/batch 126.03 | loss  1.98 | ppl     7.23|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  3.79s | valid loss  1.54 | valid ppl     4.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |     1/    9 batches | lr 1.59 | ms/batch 596.14 | loss  3.26 | ppl    25.96|\n",
      "| epoch  18 |     2/    9 batches | lr 1.59 | ms/batch 298.06 | loss  1.67 | ppl     5.30|\n",
      "| epoch  18 |     3/    9 batches | lr 1.59 | ms/batch 291.07 | loss  1.67 | ppl     5.31|\n",
      "| epoch  18 |     4/    9 batches | lr 1.59 | ms/batch 295.07 | loss  1.64 | ppl     5.18|\n",
      "| epoch  18 |     5/    9 batches | lr 1.59 | ms/batch 292.07 | loss  1.67 | ppl     5.31|\n",
      "| epoch  18 |     6/    9 batches | lr 1.59 | ms/batch 286.07 | loss  1.64 | ppl     5.14|\n",
      "| epoch  18 |     7/    9 batches | lr 1.59 | ms/batch 280.06 | loss  1.61 | ppl     5.01|\n",
      "| epoch  18 |     8/    9 batches | lr 1.59 | ms/batch 282.07 | loss  1.63 | ppl     5.09|\n",
      "| epoch  18 |     9/    9 batches | lr 1.59 | ms/batch 120.02 | loss  1.95 | ppl     7.02|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  3.67s | valid loss  1.47 | valid ppl     4.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |     1/    9 batches | lr 1.51 | ms/batch 596.14 | loss  3.19 | ppl    24.19|\n",
      "| epoch  19 |     2/    9 batches | lr 1.51 | ms/batch 301.07 | loss  1.61 | ppl     5.00|\n",
      "| epoch  19 |     3/    9 batches | lr 1.51 | ms/batch 301.07 | loss  1.62 | ppl     5.06|\n",
      "| epoch  19 |     4/    9 batches | lr 1.51 | ms/batch 297.07 | loss  1.62 | ppl     5.07|\n",
      "| epoch  19 |     5/    9 batches | lr 1.51 | ms/batch 299.07 | loss  1.59 | ppl     4.89|\n",
      "| epoch  19 |     6/    9 batches | lr 1.51 | ms/batch 299.07 | loss  1.59 | ppl     4.90|\n",
      "| epoch  19 |     7/    9 batches | lr 1.51 | ms/batch 300.07 | loss  1.61 | ppl     5.02|\n",
      "| epoch  19 |     8/    9 batches | lr 1.51 | ms/batch 297.07 | loss  1.59 | ppl     4.92|\n",
      "| epoch  19 |     9/    9 batches | lr 1.51 | ms/batch 130.03 | loss  1.92 | ppl     6.83|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  3.77s | valid loss  1.47 | valid ppl     4.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |     1/    9 batches | lr 1.43 | ms/batch 600.15 | loss  3.16 | ppl    23.67|\n",
      "| epoch  20 |     2/    9 batches | lr 1.43 | ms/batch 300.07 | loss  1.60 | ppl     4.97|\n",
      "| epoch  20 |     3/    9 batches | lr 1.43 | ms/batch 300.07 | loss  1.59 | ppl     4.90|\n",
      "| epoch  20 |     4/    9 batches | lr 1.43 | ms/batch 299.08 | loss  1.58 | ppl     4.86|\n",
      "| epoch  20 |     5/    9 batches | lr 1.43 | ms/batch 302.06 | loss  1.58 | ppl     4.88|\n",
      "| epoch  20 |     6/    9 batches | lr 1.43 | ms/batch 299.07 | loss  1.59 | ppl     4.89|\n",
      "| epoch  20 |     7/    9 batches | lr 1.43 | ms/batch 295.07 | loss  1.54 | ppl     4.67|\n",
      "| epoch  20 |     8/    9 batches | lr 1.43 | ms/batch 291.06 | loss  1.56 | ppl     4.74|\n",
      "| epoch  20 |     9/    9 batches | lr 1.43 | ms/batch 120.03 | loss  1.88 | ppl     6.54|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  3.72s | valid loss  1.39 | valid ppl     4.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |     1/    9 batches | lr 1.36 | ms/batch 563.90 | loss  3.06 | ppl    21.24|\n",
      "| epoch  21 |     2/    9 batches | lr 1.36 | ms/batch 279.73 | loss  1.52 | ppl     4.58|\n",
      "| epoch  21 |     3/    9 batches | lr 1.36 | ms/batch 281.18 | loss  1.55 | ppl     4.72|\n",
      "| epoch  21 |     4/    9 batches | lr 1.36 | ms/batch 281.07 | loss  1.58 | ppl     4.86|\n",
      "| epoch  21 |     5/    9 batches | lr 1.36 | ms/batch 280.06 | loss  1.56 | ppl     4.74|\n",
      "| epoch  21 |     6/    9 batches | lr 1.36 | ms/batch 280.05 | loss  1.55 | ppl     4.72|\n",
      "| epoch  21 |     7/    9 batches | lr 1.36 | ms/batch 281.06 | loss  1.55 | ppl     4.72|\n",
      "| epoch  21 |     8/    9 batches | lr 1.36 | ms/batch 281.06 | loss  1.55 | ppl     4.70|\n",
      "| epoch  21 |     9/    9 batches | lr 1.36 | ms/batch 118.03 | loss  1.86 | ppl     6.41|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  3.54s | valid loss  1.37 | valid ppl     3.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |     1/    9 batches | lr 1.29 | ms/batch 562.14 | loss  3.01 | ppl    20.34|\n",
      "| epoch  22 |     2/    9 batches | lr 1.29 | ms/batch 280.07 | loss  1.51 | ppl     4.53|\n",
      "| epoch  22 |     3/    9 batches | lr 1.29 | ms/batch 285.06 | loss  1.51 | ppl     4.54|\n",
      "| epoch  22 |     4/    9 batches | lr 1.29 | ms/batch 283.06 | loss  1.53 | ppl     4.61|\n",
      "| epoch  22 |     5/    9 batches | lr 1.29 | ms/batch 281.06 | loss  1.53 | ppl     4.60|\n",
      "| epoch  22 |     6/    9 batches | lr 1.29 | ms/batch 282.17 | loss  1.53 | ppl     4.63|\n",
      "| epoch  22 |     7/    9 batches | lr 1.29 | ms/batch 298.08 | loss  1.53 | ppl     4.61|\n",
      "| epoch  22 |     8/    9 batches | lr 1.29 | ms/batch 300.68 | loss  1.53 | ppl     4.60|\n",
      "| epoch  22 |     9/    9 batches | lr 1.29 | ms/batch 128.03 | loss  1.84 | ppl     6.27|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  3.65s | valid loss  1.34 | valid ppl     3.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |     1/    9 batches | lr 1.23 | ms/batch 598.14 | loss  2.97 | ppl    19.49|\n",
      "| epoch  23 |     2/    9 batches | lr 1.23 | ms/batch 299.07 | loss  1.48 | ppl     4.38|\n",
      "| epoch  23 |     3/    9 batches | lr 1.23 | ms/batch 301.07 | loss  1.50 | ppl     4.50|\n",
      "| epoch  23 |     4/    9 batches | lr 1.23 | ms/batch 301.07 | loss  1.52 | ppl     4.58|\n",
      "| epoch  23 |     5/    9 batches | lr 1.23 | ms/batch 300.06 | loss  1.51 | ppl     4.51|\n",
      "| epoch  23 |     6/    9 batches | lr 1.23 | ms/batch 301.07 | loss  1.50 | ppl     4.47|\n",
      "| epoch  23 |     7/    9 batches | lr 1.23 | ms/batch 298.08 | loss  1.50 | ppl     4.48|\n",
      "| epoch  23 |     8/    9 batches | lr 1.23 | ms/batch 300.06 | loss  1.49 | ppl     4.46|\n",
      "| epoch  23 |     9/    9 batches | lr 1.23 | ms/batch 129.03 | loss  1.81 | ppl     6.08|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  3.78s | valid loss  1.31 | valid ppl     3.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |     1/    9 batches | lr 1.17 | ms/batch 592.14 | loss  2.93 | ppl    18.73|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  24 |     2/    9 batches | lr 1.17 | ms/batch 301.07 | loss  1.45 | ppl     4.28|\n",
      "| epoch  24 |     3/    9 batches | lr 1.17 | ms/batch 295.08 | loss  1.46 | ppl     4.31|\n",
      "| epoch  24 |     4/    9 batches | lr 1.17 | ms/batch 297.06 | loss  1.48 | ppl     4.39|\n",
      "| epoch  24 |     5/    9 batches | lr 1.17 | ms/batch 296.07 | loss  1.48 | ppl     4.41|\n",
      "| epoch  24 |     6/    9 batches | lr 1.17 | ms/batch 296.08 | loss  1.49 | ppl     4.42|\n",
      "| epoch  24 |     7/    9 batches | lr 1.17 | ms/batch 284.07 | loss  1.48 | ppl     4.37|\n",
      "| epoch  24 |     8/    9 batches | lr 1.17 | ms/batch 283.06 | loss  1.47 | ppl     4.35|\n",
      "| epoch  24 |     9/    9 batches | lr 1.17 | ms/batch 119.02 | loss  1.80 | ppl     6.04|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  3.68s | valid loss  1.29 | valid ppl     3.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |     1/    9 batches | lr 1.11 | ms/batch 582.13 | loss  2.89 | ppl    17.93|\n",
      "| epoch  25 |     2/    9 batches | lr 1.11 | ms/batch 287.07 | loss  1.44 | ppl     4.23|\n",
      "| epoch  25 |     3/    9 batches | lr 1.11 | ms/batch 288.07 | loss  1.48 | ppl     4.38|\n",
      "| epoch  25 |     4/    9 batches | lr 1.11 | ms/batch 296.07 | loss  1.48 | ppl     4.37|\n",
      "| epoch  25 |     5/    9 batches | lr 1.11 | ms/batch 285.06 | loss  1.45 | ppl     4.28|\n",
      "| epoch  25 |     6/    9 batches | lr 1.11 | ms/batch 286.06 | loss  1.45 | ppl     4.27|\n",
      "| epoch  25 |     7/    9 batches | lr 1.11 | ms/batch 283.06 | loss  1.46 | ppl     4.32|\n",
      "| epoch  25 |     8/    9 batches | lr 1.11 | ms/batch 283.07 | loss  1.46 | ppl     4.29|\n",
      "| epoch  25 |     9/    9 batches | lr 1.11 | ms/batch 120.02 | loss  1.78 | ppl     5.91|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  3.61s | valid loss  1.26 | valid ppl     3.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |     1/    9 batches | lr 1.05 | ms/batch 563.13 | loss  2.86 | ppl    17.47|\n",
      "| epoch  26 |     2/    9 batches | lr 1.05 | ms/batch 285.07 | loss  1.43 | ppl     4.18|\n",
      "| epoch  26 |     3/    9 batches | lr 1.05 | ms/batch 290.06 | loss  1.44 | ppl     4.21|\n",
      "| epoch  26 |     4/    9 batches | lr 1.05 | ms/batch 282.06 | loss  1.44 | ppl     4.21|\n",
      "| epoch  26 |     5/    9 batches | lr 1.05 | ms/batch 286.07 | loss  1.45 | ppl     4.28|\n",
      "| epoch  26 |     6/    9 batches | lr 1.05 | ms/batch 284.53 | loss  1.44 | ppl     4.23|\n",
      "| epoch  26 |     7/    9 batches | lr 1.05 | ms/batch 283.07 | loss  1.42 | ppl     4.15|\n",
      "| epoch  26 |     8/    9 batches | lr 1.05 | ms/batch 283.06 | loss  1.43 | ppl     4.18|\n",
      "| epoch  26 |     9/    9 batches | lr 1.05 | ms/batch 118.03 | loss  1.73 | ppl     5.66|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  3.56s | valid loss  1.24 | valid ppl     3.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |     1/    9 batches | lr 1.00 | ms/batch 563.13 | loss  2.84 | ppl    17.04|\n",
      "| epoch  27 |     2/    9 batches | lr 1.00 | ms/batch 281.06 | loss  1.41 | ppl     4.12|\n",
      "| epoch  27 |     3/    9 batches | lr 1.00 | ms/batch 281.06 | loss  1.42 | ppl     4.14|\n",
      "| epoch  27 |     4/    9 batches | lr 1.00 | ms/batch 281.06 | loss  1.43 | ppl     4.18|\n",
      "| epoch  27 |     5/    9 batches | lr 1.00 | ms/batch 281.06 | loss  1.43 | ppl     4.17|\n",
      "| epoch  27 |     6/    9 batches | lr 1.00 | ms/batch 281.06 | loss  1.41 | ppl     4.11|\n",
      "| epoch  27 |     7/    9 batches | lr 1.00 | ms/batch 290.07 | loss  1.42 | ppl     4.12|\n",
      "| epoch  27 |     8/    9 batches | lr 1.00 | ms/batch 296.07 | loss  1.40 | ppl     4.04|\n",
      "| epoch  27 |     9/    9 batches | lr 1.00 | ms/batch 122.03 | loss  1.71 | ppl     5.53|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  3.62s | valid loss  1.21 | valid ppl     3.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |     1/    9 batches | lr 0.95 | ms/batch 582.14 | loss  2.79 | ppl    16.35|\n",
      "| epoch  28 |     2/    9 batches | lr 0.95 | ms/batch 281.05 | loss  1.39 | ppl     4.01|\n",
      "| epoch  28 |     3/    9 batches | lr 0.95 | ms/batch 282.06 | loss  1.38 | ppl     3.98|\n",
      "| epoch  28 |     4/    9 batches | lr 0.95 | ms/batch 282.06 | loss  1.40 | ppl     4.05|\n",
      "| epoch  28 |     5/    9 batches | lr 0.95 | ms/batch 281.06 | loss  1.40 | ppl     4.06|\n",
      "| epoch  28 |     6/    9 batches | lr 0.95 | ms/batch 282.06 | loss  1.40 | ppl     4.05|\n",
      "| epoch  28 |     7/    9 batches | lr 0.95 | ms/batch 284.06 | loss  1.41 | ppl     4.08|\n",
      "| epoch  28 |     8/    9 batches | lr 0.95 | ms/batch 300.07 | loss  1.39 | ppl     4.03|\n",
      "| epoch  28 |     9/    9 batches | lr 0.95 | ms/batch 127.03 | loss  1.71 | ppl     5.52|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  3.59s | valid loss  1.20 | valid ppl     3.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |     1/    9 batches | lr 0.90 | ms/batch 561.13 | loss  2.76 | ppl    15.88|\n",
      "| epoch  29 |     2/    9 batches | lr 0.90 | ms/batch 282.06 | loss  1.39 | ppl     4.00|\n",
      "| epoch  29 |     3/    9 batches | lr 0.90 | ms/batch 282.06 | loss  1.38 | ppl     3.99|\n",
      "| epoch  29 |     4/    9 batches | lr 0.90 | ms/batch 283.06 | loss  1.40 | ppl     4.06|\n",
      "| epoch  29 |     5/    9 batches | lr 0.90 | ms/batch 284.07 | loss  1.41 | ppl     4.11|\n",
      "| epoch  29 |     6/    9 batches | lr 0.90 | ms/batch 283.06 | loss  1.39 | ppl     4.02|\n",
      "| epoch  29 |     7/    9 batches | lr 0.90 | ms/batch 282.06 | loss  1.40 | ppl     4.05|\n",
      "| epoch  29 |     8/    9 batches | lr 0.90 | ms/batch 281.06 | loss  1.39 | ppl     4.03|\n",
      "| epoch  29 |     9/    9 batches | lr 0.90 | ms/batch 118.03 | loss  1.70 | ppl     5.47|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  3.56s | valid loss  1.17 | valid ppl     3.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |     1/    9 batches | lr 0.86 | ms/batch 571.13 | loss  2.74 | ppl    15.45|\n",
      "| epoch  30 |     2/    9 batches | lr 0.86 | ms/batch 283.06 | loss  1.36 | ppl     3.91|\n",
      "| epoch  30 |     3/    9 batches | lr 0.86 | ms/batch 288.07 | loss  1.37 | ppl     3.92|\n",
      "| epoch  30 |     4/    9 batches | lr 0.86 | ms/batch 281.06 | loss  1.36 | ppl     3.88|\n",
      "| epoch  30 |     5/    9 batches | lr 0.86 | ms/batch 282.06 | loss  1.36 | ppl     3.91|\n",
      "| epoch  30 |     6/    9 batches | lr 0.86 | ms/batch 283.06 | loss  1.37 | ppl     3.94|\n",
      "| epoch  30 |     7/    9 batches | lr 0.86 | ms/batch 285.06 | loss  1.37 | ppl     3.94|\n",
      "| epoch  30 |     8/    9 batches | lr 0.86 | ms/batch 283.06 | loss  1.36 | ppl     3.89|\n",
      "| epoch  30 |     9/    9 batches | lr 0.86 | ms/batch 119.03 | loss  1.68 | ppl     5.38|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  3.57s | valid loss  1.16 | valid ppl     3.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |     1/    9 batches | lr 0.82 | ms/batch 562.13 | loss  2.71 | ppl    15.08|\n",
      "| epoch  31 |     2/    9 batches | lr 0.82 | ms/batch 282.06 | loss  1.36 | ppl     3.89|\n",
      "| epoch  31 |     3/    9 batches | lr 0.82 | ms/batch 282.06 | loss  1.36 | ppl     3.91|\n",
      "| epoch  31 |     4/    9 batches | lr 0.82 | ms/batch 281.06 | loss  1.37 | ppl     3.92|\n",
      "| epoch  31 |     5/    9 batches | lr 0.82 | ms/batch 280.06 | loss  1.36 | ppl     3.90|\n",
      "| epoch  31 |     6/    9 batches | lr 0.82 | ms/batch 281.06 | loss  1.36 | ppl     3.88|\n",
      "| epoch  31 |     7/    9 batches | lr 0.82 | ms/batch 281.06 | loss  1.36 | ppl     3.90|\n",
      "| epoch  31 |     8/    9 batches | lr 0.82 | ms/batch 282.06 | loss  1.36 | ppl     3.90|\n",
      "| epoch  31 |     9/    9 batches | lr 0.82 | ms/batch 119.03 | loss  1.65 | ppl     5.20|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  3.54s | valid loss  1.14 | valid ppl     3.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |     1/    9 batches | lr 0.77 | ms/batch 595.13 | loss  2.70 | ppl    14.81|\n",
      "| epoch  32 |     2/    9 batches | lr 0.77 | ms/batch 295.07 | loss  1.34 | ppl     3.83|\n",
      "| epoch  32 |     3/    9 batches | lr 0.77 | ms/batch 302.07 | loss  1.33 | ppl     3.79|\n",
      "| epoch  32 |     4/    9 batches | lr 0.77 | ms/batch 292.07 | loss  1.34 | ppl     3.83|\n",
      "| epoch  32 |     5/    9 batches | lr 0.77 | ms/batch 289.07 | loss  1.33 | ppl     3.79|\n",
      "| epoch  32 |     6/    9 batches | lr 0.77 | ms/batch 281.06 | loss  1.35 | ppl     3.85|\n",
      "| epoch  32 |     7/    9 batches | lr 0.77 | ms/batch 287.07 | loss  1.34 | ppl     3.83|\n",
      "| epoch  32 |     8/    9 batches | lr 0.77 | ms/batch 280.06 | loss  1.35 | ppl     3.86|\n",
      "| epoch  32 |     9/    9 batches | lr 0.77 | ms/batch 119.03 | loss  1.64 | ppl     5.16|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  3.64s | valid loss  1.13 | valid ppl     3.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |     1/    9 batches | lr 0.74 | ms/batch 578.13 | loss  2.65 | ppl    14.22|\n",
      "| epoch  33 |     2/    9 batches | lr 0.74 | ms/batch 285.07 | loss  1.33 | ppl     3.79|\n",
      "| epoch  33 |     3/    9 batches | lr 0.74 | ms/batch 288.93 | loss  1.33 | ppl     3.80|\n",
      "| epoch  33 |     4/    9 batches | lr 0.74 | ms/batch 283.07 | loss  1.33 | ppl     3.79|\n",
      "| epoch  33 |     5/    9 batches | lr 0.74 | ms/batch 285.06 | loss  1.33 | ppl     3.77|\n",
      "| epoch  33 |     6/    9 batches | lr 0.74 | ms/batch 285.06 | loss  1.33 | ppl     3.77|\n",
      "| epoch  33 |     7/    9 batches | lr 0.74 | ms/batch 282.06 | loss  1.33 | ppl     3.78|\n",
      "| epoch  33 |     8/    9 batches | lr 0.74 | ms/batch 286.06 | loss  1.33 | ppl     3.79|\n",
      "| epoch  33 |     9/    9 batches | lr 0.74 | ms/batch 122.03 | loss  1.64 | ppl     5.17|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  3.59s | valid loss  1.11 | valid ppl     3.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |     1/    9 batches | lr 0.70 | ms/batch 573.14 | loss  2.66 | ppl    14.32|\n",
      "| epoch  34 |     2/    9 batches | lr 0.70 | ms/batch 294.06 | loss  1.32 | ppl     3.73|\n",
      "| epoch  34 |     3/    9 batches | lr 0.70 | ms/batch 293.07 | loss  1.31 | ppl     3.71|\n",
      "| epoch  34 |     4/    9 batches | lr 0.70 | ms/batch 288.07 | loss  1.32 | ppl     3.74|\n",
      "| epoch  34 |     5/    9 batches | lr 0.70 | ms/batch 281.05 | loss  1.31 | ppl     3.71|\n",
      "| epoch  34 |     6/    9 batches | lr 0.70 | ms/batch 281.06 | loss  1.31 | ppl     3.72|\n",
      "| epoch  34 |     7/    9 batches | lr 0.70 | ms/batch 289.07 | loss  1.32 | ppl     3.76|\n",
      "| epoch  34 |     8/    9 batches | lr 0.70 | ms/batch 286.07 | loss  1.31 | ppl     3.71|\n",
      "| epoch  34 |     9/    9 batches | lr 0.70 | ms/batch 118.03 | loss  1.62 | ppl     5.04|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  3.60s | valid loss  1.10 | valid ppl     3.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |     1/    9 batches | lr 0.66 | ms/batch 565.13 | loss  2.62 | ppl    13.74|\n",
      "| epoch  35 |     2/    9 batches | lr 0.66 | ms/batch 281.06 | loss  1.31 | ppl     3.69|\n",
      "| epoch  35 |     3/    9 batches | lr 0.66 | ms/batch 282.06 | loss  1.31 | ppl     3.72|\n",
      "| epoch  35 |     4/    9 batches | lr 0.66 | ms/batch 283.06 | loss  1.32 | ppl     3.73|\n",
      "| epoch  35 |     5/    9 batches | lr 0.66 | ms/batch 281.06 | loss  1.30 | ppl     3.69|\n",
      "| epoch  35 |     6/    9 batches | lr 0.66 | ms/batch 288.07 | loss  1.31 | ppl     3.72|\n",
      "| epoch  35 |     7/    9 batches | lr 0.66 | ms/batch 282.06 | loss  1.30 | ppl     3.66|\n",
      "| epoch  35 |     8/    9 batches | lr 0.66 | ms/batch 286.06 | loss  1.31 | ppl     3.69|\n",
      "| epoch  35 |     9/    9 batches | lr 0.66 | ms/batch 125.03 | loss  1.61 | ppl     4.98|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  3.61s | valid loss  1.09 | valid ppl     2.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |     1/    9 batches | lr 0.63 | ms/batch 589.13 | loss  2.60 | ppl    13.51|\n",
      "| epoch  36 |     2/    9 batches | lr 0.63 | ms/batch 295.07 | loss  1.29 | ppl     3.63|\n",
      "| epoch  36 |     3/    9 batches | lr 0.63 | ms/batch 292.07 | loss  1.31 | ppl     3.70|\n",
      "| epoch  36 |     4/    9 batches | lr 0.63 | ms/batch 297.08 | loss  1.31 | ppl     3.69|\n",
      "| epoch  36 |     5/    9 batches | lr 0.63 | ms/batch 289.07 | loss  1.29 | ppl     3.65|\n",
      "| epoch  36 |     6/    9 batches | lr 0.63 | ms/batch 292.06 | loss  1.30 | ppl     3.69|\n",
      "| epoch  36 |     7/    9 batches | lr 0.63 | ms/batch 293.08 | loss  1.29 | ppl     3.64|\n",
      "| epoch  36 |     8/    9 batches | lr 0.63 | ms/batch 295.06 | loss  1.29 | ppl     3.62|\n",
      "| epoch  36 |     9/    9 batches | lr 0.63 | ms/batch 122.03 | loss  1.59 | ppl     4.92|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  3.69s | valid loss  1.08 | valid ppl     2.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |     1/    9 batches | lr 0.60 | ms/batch 594.14 | loss  2.58 | ppl    13.21|\n",
      "| epoch  37 |     2/    9 batches | lr 0.60 | ms/batch 296.08 | loss  1.30 | ppl     3.65|\n",
      "| epoch  37 |     3/    9 batches | lr 0.60 | ms/batch 296.06 | loss  1.30 | ppl     3.67|\n",
      "| epoch  37 |     4/    9 batches | lr 0.60 | ms/batch 299.07 | loss  1.28 | ppl     3.59|\n",
      "| epoch  37 |     5/    9 batches | lr 0.60 | ms/batch 297.07 | loss  1.30 | ppl     3.66|\n",
      "| epoch  37 |     6/    9 batches | lr 0.60 | ms/batch 300.07 | loss  1.30 | ppl     3.67|\n",
      "| epoch  37 |     7/    9 batches | lr 0.60 | ms/batch 288.07 | loss  1.29 | ppl     3.64|\n",
      "| epoch  37 |     8/    9 batches | lr 0.60 | ms/batch 282.06 | loss  1.28 | ppl     3.61|\n",
      "| epoch  37 |     9/    9 batches | lr 0.60 | ms/batch 116.03 | loss  1.60 | ppl     4.97|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  3.67s | valid loss  1.06 | valid ppl     2.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |     1/    9 batches | lr 0.57 | ms/batch 579.13 | loss  2.56 | ppl    12.98|\n",
      "| epoch  38 |     2/    9 batches | lr 0.57 | ms/batch 297.07 | loss  1.30 | ppl     3.66|\n",
      "| epoch  38 |     3/    9 batches | lr 0.57 | ms/batch 286.06 | loss  1.28 | ppl     3.60|\n",
      "| epoch  38 |     4/    9 batches | lr 0.57 | ms/batch 279.06 | loss  1.29 | ppl     3.62|\n",
      "| epoch  38 |     5/    9 batches | lr 0.57 | ms/batch 288.07 | loss  1.28 | ppl     3.58|\n",
      "| epoch  38 |     6/    9 batches | lr 0.57 | ms/batch 288.06 | loss  1.28 | ppl     3.60|\n",
      "| epoch  38 |     7/    9 batches | lr 0.57 | ms/batch 291.07 | loss  1.29 | ppl     3.64|\n",
      "| epoch  38 |     8/    9 batches | lr 0.57 | ms/batch 283.06 | loss  1.29 | ppl     3.62|\n",
      "| epoch  38 |     9/    9 batches | lr 0.57 | ms/batch 119.03 | loss  1.57 | ppl     4.81|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  3.60s | valid loss  1.05 | valid ppl     2.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |     1/    9 batches | lr 0.54 | ms/batch 559.13 | loss  2.55 | ppl    12.77|\n",
      "| epoch  39 |     2/    9 batches | lr 0.54 | ms/batch 280.06 | loss  1.27 | ppl     3.57|\n",
      "| epoch  39 |     3/    9 batches | lr 0.54 | ms/batch 279.06 | loss  1.28 | ppl     3.59|\n",
      "| epoch  39 |     4/    9 batches | lr 0.54 | ms/batch 280.06 | loss  1.28 | ppl     3.59|\n",
      "| epoch  39 |     5/    9 batches | lr 0.54 | ms/batch 280.06 | loss  1.28 | ppl     3.58|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  39 |     6/    9 batches | lr 0.54 | ms/batch 280.06 | loss  1.29 | ppl     3.62|\n",
      "| epoch  39 |     7/    9 batches | lr 0.54 | ms/batch 281.06 | loss  1.28 | ppl     3.61|\n",
      "| epoch  39 |     8/    9 batches | lr 0.54 | ms/batch 281.06 | loss  1.27 | ppl     3.55|\n",
      "| epoch  39 |     9/    9 batches | lr 0.54 | ms/batch 119.03 | loss  1.56 | ppl     4.75|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  3.53s | valid loss  1.05 | valid ppl     2.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |     1/    9 batches | lr 0.51 | ms/batch 562.13 | loss  2.56 | ppl    12.89|\n",
      "| epoch  40 |     2/    9 batches | lr 0.51 | ms/batch 281.06 | loss  1.28 | ppl     3.59|\n",
      "| epoch  40 |     3/    9 batches | lr 0.51 | ms/batch 281.06 | loss  1.27 | ppl     3.56|\n",
      "| epoch  40 |     4/    9 batches | lr 0.51 | ms/batch 280.06 | loss  1.27 | ppl     3.58|\n",
      "| epoch  40 |     5/    9 batches | lr 0.51 | ms/batch 281.84 | loss  1.27 | ppl     3.55|\n",
      "| epoch  40 |     6/    9 batches | lr 0.51 | ms/batch 279.75 | loss  1.26 | ppl     3.53|\n",
      "| epoch  40 |     7/    9 batches | lr 0.51 | ms/batch 283.06 | loss  1.27 | ppl     3.55|\n",
      "| epoch  40 |     8/    9 batches | lr 0.51 | ms/batch 289.07 | loss  1.27 | ppl     3.56|\n",
      "| epoch  40 |     9/    9 batches | lr 0.51 | ms/batch 120.03 | loss  1.54 | ppl     4.67|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  3.56s | valid loss  1.03 | valid ppl     2.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |     1/    9 batches | lr 0.49 | ms/batch 581.14 | loss  2.52 | ppl    12.45|\n",
      "| epoch  41 |     2/    9 batches | lr 0.49 | ms/batch 282.99 | loss  1.26 | ppl     3.53|\n",
      "| epoch  41 |     3/    9 batches | lr 0.49 | ms/batch 280.06 | loss  1.26 | ppl     3.53|\n",
      "| epoch  41 |     4/    9 batches | lr 0.49 | ms/batch 281.44 | loss  1.27 | ppl     3.55|\n",
      "| epoch  41 |     5/    9 batches | lr 0.49 | ms/batch 280.06 | loss  1.26 | ppl     3.53|\n",
      "| epoch  41 |     6/    9 batches | lr 0.49 | ms/batch 280.99 | loss  1.25 | ppl     3.49|\n",
      "| epoch  41 |     7/    9 batches | lr 0.49 | ms/batch 281.06 | loss  1.26 | ppl     3.52|\n",
      "| epoch  41 |     8/    9 batches | lr 0.49 | ms/batch 279.06 | loss  1.26 | ppl     3.52|\n",
      "| epoch  41 |     9/    9 batches | lr 0.49 | ms/batch 119.03 | loss  1.55 | ppl     4.71|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  3.55s | valid loss  1.02 | valid ppl     2.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |     1/    9 batches | lr 0.46 | ms/batch 561.13 | loss  2.51 | ppl    12.32|\n",
      "| epoch  42 |     2/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.26 | ppl     3.52|\n",
      "| epoch  42 |     3/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.25 | ppl     3.49|\n",
      "| epoch  42 |     4/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.26 | ppl     3.51|\n",
      "| epoch  42 |     5/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.25 | ppl     3.50|\n",
      "| epoch  42 |     6/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.25 | ppl     3.50|\n",
      "| epoch  42 |     7/    9 batches | lr 0.46 | ms/batch 283.06 | loss  1.26 | ppl     3.53|\n",
      "| epoch  42 |     8/    9 batches | lr 0.46 | ms/batch 281.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  42 |     9/    9 batches | lr 0.46 | ms/batch 118.03 | loss  1.55 | ppl     4.72|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  3.53s | valid loss  1.01 | valid ppl     2.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |     1/    9 batches | lr 0.44 | ms/batch 573.13 | loss  2.51 | ppl    12.27|\n",
      "| epoch  43 |     2/    9 batches | lr 0.44 | ms/batch 280.71 | loss  1.25 | ppl     3.48|\n",
      "| epoch  43 |     3/    9 batches | lr 0.44 | ms/batch 294.07 | loss  1.24 | ppl     3.47|\n",
      "| epoch  43 |     4/    9 batches | lr 0.44 | ms/batch 281.07 | loss  1.26 | ppl     3.51|\n",
      "| epoch  43 |     5/    9 batches | lr 0.44 | ms/batch 281.05 | loss  1.24 | ppl     3.47|\n",
      "| epoch  43 |     6/    9 batches | lr 0.44 | ms/batch 280.06 | loss  1.25 | ppl     3.48|\n",
      "| epoch  43 |     7/    9 batches | lr 0.44 | ms/batch 280.06 | loss  1.25 | ppl     3.49|\n",
      "| epoch  43 |     8/    9 batches | lr 0.44 | ms/batch 280.07 | loss  1.24 | ppl     3.47|\n",
      "| epoch  43 |     9/    9 batches | lr 0.44 | ms/batch 119.02 | loss  1.51 | ppl     4.51|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  3.56s | valid loss  1.00 | valid ppl     2.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |     1/    9 batches | lr 0.42 | ms/batch 561.13 | loss  2.50 | ppl    12.13|\n",
      "| epoch  44 |     2/    9 batches | lr 0.42 | ms/batch 281.06 | loss  1.24 | ppl     3.47|\n",
      "| epoch  44 |     3/    9 batches | lr 0.42 | ms/batch 280.05 | loss  1.25 | ppl     3.48|\n",
      "| epoch  44 |     4/    9 batches | lr 0.42 | ms/batch 280.06 | loss  1.23 | ppl     3.44|\n",
      "| epoch  44 |     5/    9 batches | lr 0.42 | ms/batch 280.06 | loss  1.24 | ppl     3.45|\n",
      "| epoch  44 |     6/    9 batches | lr 0.42 | ms/batch 279.06 | loss  1.25 | ppl     3.49|\n",
      "| epoch  44 |     7/    9 batches | lr 0.42 | ms/batch 281.06 | loss  1.24 | ppl     3.45|\n",
      "| epoch  44 |     8/    9 batches | lr 0.42 | ms/batch 280.76 | loss  1.25 | ppl     3.48|\n",
      "| epoch  44 |     9/    9 batches | lr 0.42 | ms/batch 119.03 | loss  1.53 | ppl     4.62|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  3.53s | valid loss  1.00 | valid ppl     2.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |     1/    9 batches | lr 0.40 | ms/batch 560.13 | loss  2.46 | ppl    11.75|\n",
      "| epoch  45 |     2/    9 batches | lr 0.40 | ms/batch 281.06 | loss  1.23 | ppl     3.42|\n",
      "| epoch  45 |     3/    9 batches | lr 0.40 | ms/batch 280.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  45 |     4/    9 batches | lr 0.40 | ms/batch 279.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  45 |     5/    9 batches | lr 0.40 | ms/batch 281.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  45 |     6/    9 batches | lr 0.40 | ms/batch 281.06 | loss  1.23 | ppl     3.44|\n",
      "| epoch  45 |     7/    9 batches | lr 0.40 | ms/batch 280.06 | loss  1.23 | ppl     3.44|\n",
      "| epoch  45 |     8/    9 batches | lr 0.40 | ms/batch 279.06 | loss  1.24 | ppl     3.44|\n",
      "| epoch  45 |     9/    9 batches | lr 0.40 | ms/batch 119.03 | loss  1.53 | ppl     4.62|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  3.53s | valid loss  0.99 | valid ppl     2.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |     1/    9 batches | lr 0.38 | ms/batch 563.13 | loss  2.47 | ppl    11.88|\n",
      "| epoch  46 |     2/    9 batches | lr 0.38 | ms/batch 281.06 | loss  1.24 | ppl     3.44|\n",
      "| epoch  46 |     3/    9 batches | lr 0.38 | ms/batch 281.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  46 |     4/    9 batches | lr 0.38 | ms/batch 282.07 | loss  1.24 | ppl     3.47|\n",
      "| epoch  46 |     5/    9 batches | lr 0.38 | ms/batch 281.06 | loss  1.22 | ppl     3.38|\n",
      "| epoch  46 |     6/    9 batches | lr 0.38 | ms/batch 280.06 | loss  1.24 | ppl     3.46|\n",
      "| epoch  46 |     7/    9 batches | lr 0.38 | ms/batch 281.06 | loss  1.23 | ppl     3.41|\n",
      "| epoch  46 |     8/    9 batches | lr 0.38 | ms/batch 281.06 | loss  1.22 | ppl     3.40|\n",
      "| epoch  46 |     9/    9 batches | lr 0.38 | ms/batch 119.03 | loss  1.51 | ppl     4.51|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  3.54s | valid loss  0.98 | valid ppl     2.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |     1/    9 batches | lr 0.36 | ms/batch 562.13 | loss  2.45 | ppl    11.55|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  47 |     2/    9 batches | lr 0.36 | ms/batch 280.06 | loss  1.23 | ppl     3.41|\n",
      "| epoch  47 |     3/    9 batches | lr 0.36 | ms/batch 281.06 | loss  1.22 | ppl     3.39|\n",
      "| epoch  47 |     4/    9 batches | lr 0.36 | ms/batch 281.06 | loss  1.24 | ppl     3.45|\n",
      "| epoch  47 |     5/    9 batches | lr 0.36 | ms/batch 282.06 | loss  1.22 | ppl     3.40|\n",
      "| epoch  47 |     6/    9 batches | lr 0.36 | ms/batch 280.06 | loss  1.23 | ppl     3.41|\n",
      "| epoch  47 |     7/    9 batches | lr 0.36 | ms/batch 279.96 | loss  1.22 | ppl     3.40|\n",
      "| epoch  47 |     8/    9 batches | lr 0.36 | ms/batch 281.07 | loss  1.22 | ppl     3.39|\n",
      "| epoch  47 |     9/    9 batches | lr 0.36 | ms/batch 118.02 | loss  1.50 | ppl     4.49|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  3.53s | valid loss  0.98 | valid ppl     2.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |     1/    9 batches | lr 0.34 | ms/batch 562.13 | loss  2.46 | ppl    11.69|\n",
      "| epoch  48 |     2/    9 batches | lr 0.34 | ms/batch 280.07 | loss  1.22 | ppl     3.38|\n",
      "| epoch  48 |     3/    9 batches | lr 0.34 | ms/batch 280.06 | loss  1.22 | ppl     3.40|\n",
      "| epoch  48 |     4/    9 batches | lr 0.34 | ms/batch 279.06 | loss  1.23 | ppl     3.41|\n",
      "| epoch  48 |     5/    9 batches | lr 0.34 | ms/batch 280.07 | loss  1.22 | ppl     3.38|\n",
      "| epoch  48 |     6/    9 batches | lr 0.34 | ms/batch 279.06 | loss  1.22 | ppl     3.39|\n",
      "| epoch  48 |     7/    9 batches | lr 0.34 | ms/batch 281.06 | loss  1.22 | ppl     3.39|\n",
      "| epoch  48 |     8/    9 batches | lr 0.34 | ms/batch 281.06 | loss  1.21 | ppl     3.36|\n",
      "| epoch  48 |     9/    9 batches | lr 0.34 | ms/batch 120.02 | loss  1.51 | ppl     4.51|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  3.53s | valid loss  0.97 | valid ppl     2.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |     1/    9 batches | lr 0.32 | ms/batch 561.14 | loss  2.44 | ppl    11.49|\n",
      "| epoch  49 |     2/    9 batches | lr 0.32 | ms/batch 283.06 | loss  1.22 | ppl     3.38|\n",
      "| epoch  49 |     3/    9 batches | lr 0.32 | ms/batch 281.06 | loss  1.20 | ppl     3.34|\n",
      "| epoch  49 |     4/    9 batches | lr 0.32 | ms/batch 281.06 | loss  1.22 | ppl     3.37|\n",
      "| epoch  49 |     5/    9 batches | lr 0.32 | ms/batch 281.06 | loss  1.23 | ppl     3.41|\n",
      "| epoch  49 |     6/    9 batches | lr 0.32 | ms/batch 281.06 | loss  1.23 | ppl     3.40|\n",
      "| epoch  49 |     7/    9 batches | lr 0.32 | ms/batch 280.05 | loss  1.22 | ppl     3.38|\n",
      "| epoch  49 |     8/    9 batches | lr 0.32 | ms/batch 281.07 | loss  1.21 | ppl     3.34|\n",
      "| epoch  49 |     9/    9 batches | lr 0.32 | ms/batch 118.02 | loss  1.48 | ppl     4.39|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  3.53s | valid loss  0.97 | valid ppl     2.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |     1/    9 batches | lr 0.31 | ms/batch 560.14 | loss  2.43 | ppl    11.35|\n",
      "| epoch  50 |     2/    9 batches | lr 0.31 | ms/batch 281.06 | loss  1.21 | ppl     3.37|\n",
      "| epoch  50 |     3/    9 batches | lr 0.31 | ms/batch 280.07 | loss  1.21 | ppl     3.36|\n",
      "| epoch  50 |     4/    9 batches | lr 0.31 | ms/batch 280.07 | loss  1.22 | ppl     3.37|\n",
      "| epoch  50 |     5/    9 batches | lr 0.31 | ms/batch 280.05 | loss  1.21 | ppl     3.36|\n",
      "| epoch  50 |     6/    9 batches | lr 0.31 | ms/batch 280.07 | loss  1.23 | ppl     3.41|\n",
      "| epoch  50 |     7/    9 batches | lr 0.31 | ms/batch 281.05 | loss  1.21 | ppl     3.35|\n",
      "| epoch  50 |     8/    9 batches | lr 0.31 | ms/batch 281.07 | loss  1.21 | ppl     3.36|\n",
      "| epoch  50 |     9/    9 batches | lr 0.31 | ms/batch 119.02 | loss  1.48 | ppl     4.39|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  3.56s | valid loss  0.96 | valid ppl     2.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |     1/    9 batches | lr 0.29 | ms/batch 570.13 | loss  2.43 | ppl    11.39|\n",
      "| epoch  51 |     2/    9 batches | lr 0.29 | ms/batch 282.06 | loss  1.22 | ppl     3.40|\n",
      "| epoch  51 |     3/    9 batches | lr 0.29 | ms/batch 280.07 | loss  1.21 | ppl     3.37|\n",
      "| epoch  51 |     4/    9 batches | lr 0.29 | ms/batch 293.07 | loss  1.22 | ppl     3.39|\n",
      "| epoch  51 |     5/    9 batches | lr 0.29 | ms/batch 291.07 | loss  1.21 | ppl     3.35|\n",
      "| epoch  51 |     6/    9 batches | lr 0.29 | ms/batch 283.06 | loss  1.21 | ppl     3.36|\n",
      "| epoch  51 |     7/    9 batches | lr 0.29 | ms/batch 281.07 | loss  1.22 | ppl     3.39|\n",
      "| epoch  51 |     8/    9 batches | lr 0.29 | ms/batch 288.06 | loss  1.21 | ppl     3.36|\n",
      "| epoch  51 |     9/    9 batches | lr 0.29 | ms/batch 123.03 | loss  1.48 | ppl     4.38|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  3.60s | valid loss  0.95 | valid ppl     2.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |     1/    9 batches | lr 0.28 | ms/batch 572.14 | loss  2.41 | ppl    11.17|\n",
      "| epoch  52 |     2/    9 batches | lr 0.28 | ms/batch 280.06 | loss  1.21 | ppl     3.37|\n",
      "| epoch  52 |     3/    9 batches | lr 0.28 | ms/batch 281.06 | loss  1.20 | ppl     3.33|\n",
      "| epoch  52 |     4/    9 batches | lr 0.28 | ms/batch 281.05 | loss  1.21 | ppl     3.34|\n",
      "| epoch  52 |     5/    9 batches | lr 0.28 | ms/batch 283.06 | loss  1.20 | ppl     3.34|\n",
      "| epoch  52 |     6/    9 batches | lr 0.28 | ms/batch 281.07 | loss  1.22 | ppl     3.38|\n",
      "| epoch  52 |     7/    9 batches | lr 0.28 | ms/batch 291.07 | loss  1.21 | ppl     3.35|\n",
      "| epoch  52 |     8/    9 batches | lr 0.28 | ms/batch 284.06 | loss  1.20 | ppl     3.31|\n",
      "| epoch  52 |     9/    9 batches | lr 0.28 | ms/batch 118.03 | loss  1.48 | ppl     4.41|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  3.60s | valid loss  0.95 | valid ppl     2.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |     1/    9 batches | lr 0.26 | ms/batch 577.14 | loss  2.39 | ppl    10.90|\n",
      "| epoch  53 |     2/    9 batches | lr 0.26 | ms/batch 289.07 | loss  1.21 | ppl     3.35|\n",
      "| epoch  53 |     3/    9 batches | lr 0.26 | ms/batch 296.07 | loss  1.20 | ppl     3.30|\n",
      "| epoch  53 |     4/    9 batches | lr 0.26 | ms/batch 295.07 | loss  1.21 | ppl     3.34|\n",
      "| epoch  53 |     5/    9 batches | lr 0.26 | ms/batch 299.06 | loss  1.19 | ppl     3.30|\n",
      "| epoch  53 |     6/    9 batches | lr 0.26 | ms/batch 294.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  53 |     7/    9 batches | lr 0.26 | ms/batch 301.07 | loss  1.21 | ppl     3.34|\n",
      "| epoch  53 |     8/    9 batches | lr 0.26 | ms/batch 299.07 | loss  1.21 | ppl     3.34|\n",
      "| epoch  53 |     9/    9 batches | lr 0.26 | ms/batch 120.03 | loss  1.47 | ppl     4.34|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  3.67s | valid loss  0.95 | valid ppl     2.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |     1/    9 batches | lr 0.25 | ms/batch 580.13 | loss  2.40 | ppl    11.03|\n",
      "| epoch  54 |     2/    9 batches | lr 0.25 | ms/batch 300.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  54 |     3/    9 batches | lr 0.25 | ms/batch 302.07 | loss  1.21 | ppl     3.36|\n",
      "| epoch  54 |     4/    9 batches | lr 0.25 | ms/batch 286.06 | loss  1.20 | ppl     3.33|\n",
      "| epoch  54 |     5/    9 batches | lr 0.25 | ms/batch 300.08 | loss  1.20 | ppl     3.33|\n",
      "| epoch  54 |     6/    9 batches | lr 0.25 | ms/batch 299.06 | loss  1.20 | ppl     3.33|\n",
      "| epoch  54 |     7/    9 batches | lr 0.25 | ms/batch 298.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  54 |     8/    9 batches | lr 0.25 | ms/batch 299.06 | loss  1.20 | ppl     3.31|\n",
      "| epoch  54 |     9/    9 batches | lr 0.25 | ms/batch 124.03 | loss  1.47 | ppl     4.34|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  3.74s | valid loss  0.94 | valid ppl     2.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |     1/    9 batches | lr 0.24 | ms/batch 567.14 | loss  2.41 | ppl    11.10|\n",
      "| epoch  55 |     2/    9 batches | lr 0.24 | ms/batch 289.06 | loss  1.20 | ppl     3.31|\n",
      "| epoch  55 |     3/    9 batches | lr 0.24 | ms/batch 300.07 | loss  1.19 | ppl     3.27|\n",
      "| epoch  55 |     4/    9 batches | lr 0.24 | ms/batch 300.07 | loss  1.20 | ppl     3.31|\n",
      "| epoch  55 |     5/    9 batches | lr 0.24 | ms/batch 293.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  55 |     6/    9 batches | lr 0.24 | ms/batch 280.07 | loss  1.19 | ppl     3.30|\n",
      "| epoch  55 |     7/    9 batches | lr 0.24 | ms/batch 287.07 | loss  1.20 | ppl     3.31|\n",
      "| epoch  55 |     8/    9 batches | lr 0.24 | ms/batch 285.06 | loss  1.19 | ppl     3.28|\n",
      "| epoch  55 |     9/    9 batches | lr 0.24 | ms/batch 125.03 | loss  1.46 | ppl     4.31|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  3.67s | valid loss  0.94 | valid ppl     2.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |     1/    9 batches | lr 0.23 | ms/batch 595.14 | loss  2.39 | ppl    10.90|\n",
      "| epoch  56 |     2/    9 batches | lr 0.23 | ms/batch 301.07 | loss  1.19 | ppl     3.30|\n",
      "| epoch  56 |     3/    9 batches | lr 0.23 | ms/batch 298.08 | loss  1.20 | ppl     3.32|\n",
      "| epoch  56 |     4/    9 batches | lr 0.23 | ms/batch 294.07 | loss  1.19 | ppl     3.30|\n",
      "| epoch  56 |     5/    9 batches | lr 0.23 | ms/batch 298.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  56 |     6/    9 batches | lr 0.23 | ms/batch 296.07 | loss  1.19 | ppl     3.29|\n",
      "| epoch  56 |     7/    9 batches | lr 0.23 | ms/batch 294.08 | loss  1.20 | ppl     3.31|\n",
      "| epoch  56 |     8/    9 batches | lr 0.23 | ms/batch 285.07 | loss  1.19 | ppl     3.28|\n",
      "| epoch  56 |     9/    9 batches | lr 0.23 | ms/batch 120.02 | loss  1.47 | ppl     4.37|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  3.71s | valid loss  0.94 | valid ppl     2.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |     1/    9 batches | lr 0.21 | ms/batch 565.13 | loss  2.40 | ppl    10.97|\n",
      "| epoch  57 |     2/    9 batches | lr 0.21 | ms/batch 281.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  57 |     3/    9 batches | lr 0.21 | ms/batch 282.05 | loss  1.20 | ppl     3.31|\n",
      "| epoch  57 |     4/    9 batches | lr 0.21 | ms/batch 281.07 | loss  1.20 | ppl     3.32|\n",
      "| epoch  57 |     5/    9 batches | lr 0.21 | ms/batch 281.06 | loss  1.20 | ppl     3.33|\n",
      "| epoch  57 |     6/    9 batches | lr 0.21 | ms/batch 281.06 | loss  1.18 | ppl     3.27|\n",
      "| epoch  57 |     7/    9 batches | lr 0.21 | ms/batch 285.06 | loss  1.20 | ppl     3.32|\n",
      "| epoch  57 |     8/    9 batches | lr 0.21 | ms/batch 294.08 | loss  1.19 | ppl     3.28|\n",
      "| epoch  57 |     9/    9 batches | lr 0.21 | ms/batch 124.02 | loss  1.47 | ppl     4.37|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  3.59s | valid loss  0.93 | valid ppl     2.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |     1/    9 batches | lr 0.20 | ms/batch 562.13 | loss  2.39 | ppl    10.87|\n",
      "| epoch  58 |     2/    9 batches | lr 0.20 | ms/batch 283.07 | loss  1.19 | ppl     3.28|\n",
      "| epoch  58 |     3/    9 batches | lr 0.20 | ms/batch 282.07 | loss  1.19 | ppl     3.29|\n",
      "| epoch  58 |     4/    9 batches | lr 0.20 | ms/batch 282.06 | loss  1.20 | ppl     3.32|\n",
      "| epoch  58 |     5/    9 batches | lr 0.20 | ms/batch 289.07 | loss  1.19 | ppl     3.30|\n",
      "| epoch  58 |     6/    9 batches | lr 0.20 | ms/batch 291.07 | loss  1.19 | ppl     3.27|\n",
      "| epoch  58 |     7/    9 batches | lr 0.20 | ms/batch 282.06 | loss  1.20 | ppl     3.31|\n",
      "| epoch  58 |     8/    9 batches | lr 0.20 | ms/batch 292.07 | loss  1.18 | ppl     3.26|\n",
      "| epoch  58 |     9/    9 batches | lr 0.20 | ms/batch 121.02 | loss  1.46 | ppl     4.32|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  3.60s | valid loss  0.93 | valid ppl     2.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |     1/    9 batches | lr 0.19 | ms/batch 577.14 | loss  2.36 | ppl    10.55|\n",
      "| epoch  59 |     2/    9 batches | lr 0.19 | ms/batch 291.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  59 |     3/    9 batches | lr 0.19 | ms/batch 283.07 | loss  1.19 | ppl     3.28|\n",
      "| epoch  59 |     4/    9 batches | lr 0.19 | ms/batch 283.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  59 |     5/    9 batches | lr 0.19 | ms/batch 290.30 | loss  1.19 | ppl     3.29|\n",
      "| epoch  59 |     6/    9 batches | lr 0.19 | ms/batch 281.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  59 |     7/    9 batches | lr 0.19 | ms/batch 281.07 | loss  1.19 | ppl     3.29|\n",
      "| epoch  59 |     8/    9 batches | lr 0.19 | ms/batch 286.06 | loss  1.19 | ppl     3.28|\n",
      "| epoch  59 |     9/    9 batches | lr 0.19 | ms/batch 121.03 | loss  1.45 | ppl     4.26|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  3.61s | valid loss  0.92 | valid ppl     2.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |     1/    9 batches | lr 0.18 | ms/batch 590.14 | loss  2.37 | ppl    10.68|\n",
      "| epoch  60 |     2/    9 batches | lr 0.18 | ms/batch 286.06 | loss  1.19 | ppl     3.29|\n",
      "| epoch  60 |     3/    9 batches | lr 0.18 | ms/batch 285.06 | loss  1.19 | ppl     3.28|\n",
      "| epoch  60 |     4/    9 batches | lr 0.18 | ms/batch 296.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  60 |     5/    9 batches | lr 0.18 | ms/batch 288.06 | loss  1.19 | ppl     3.28|\n",
      "| epoch  60 |     6/    9 batches | lr 0.18 | ms/batch 285.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  60 |     7/    9 batches | lr 0.18 | ms/batch 290.07 | loss  1.18 | ppl     3.26|\n",
      "| epoch  60 |     8/    9 batches | lr 0.18 | ms/batch 283.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  60 |     9/    9 batches | lr 0.18 | ms/batch 119.03 | loss  1.46 | ppl     4.32|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  3.66s | valid loss  0.92 | valid ppl     2.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 |     1/    9 batches | lr 0.18 | ms/batch 570.13 | loss  2.36 | ppl    10.55|\n",
      "| epoch  61 |     2/    9 batches | lr 0.18 | ms/batch 309.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  61 |     3/    9 batches | lr 0.18 | ms/batch 293.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  61 |     4/    9 batches | lr 0.18 | ms/batch 315.07 | loss  1.19 | ppl     3.27|\n",
      "| epoch  61 |     5/    9 batches | lr 0.18 | ms/batch 302.08 | loss  1.18 | ppl     3.26|\n",
      "| epoch  61 |     6/    9 batches | lr 0.18 | ms/batch 284.06 | loss  1.18 | ppl     3.24|\n",
      "| epoch  61 |     7/    9 batches | lr 0.18 | ms/batch 286.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  61 |     8/    9 batches | lr 0.18 | ms/batch 296.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  61 |     9/    9 batches | lr 0.18 | ms/batch 123.03 | loss  1.47 | ppl     4.35|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  3.69s | valid loss  0.92 | valid ppl     2.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |     1/    9 batches | lr 0.17 | ms/batch 578.13 | loss  2.35 | ppl    10.53|\n",
      "| epoch  62 |     2/    9 batches | lr 0.17 | ms/batch 280.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  62 |     3/    9 batches | lr 0.17 | ms/batch 285.06 | loss  1.19 | ppl     3.28|\n",
      "| epoch  62 |     4/    9 batches | lr 0.17 | ms/batch 290.07 | loss  1.18 | ppl     3.26|\n",
      "| epoch  62 |     5/    9 batches | lr 0.17 | ms/batch 282.06 | loss  1.18 | ppl     3.24|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  62 |     6/    9 batches | lr 0.17 | ms/batch 283.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  62 |     7/    9 batches | lr 0.17 | ms/batch 289.07 | loss  1.18 | ppl     3.26|\n",
      "| epoch  62 |     8/    9 batches | lr 0.17 | ms/batch 283.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  62 |     9/    9 batches | lr 0.17 | ms/batch 122.03 | loss  1.47 | ppl     4.34|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  3.66s | valid loss  0.91 | valid ppl     2.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |     1/    9 batches | lr 0.16 | ms/batch 577.13 | loss  2.36 | ppl    10.57|\n",
      "| epoch  63 |     2/    9 batches | lr 0.16 | ms/batch 288.06 | loss  1.18 | ppl     3.24|\n",
      "| epoch  63 |     3/    9 batches | lr 0.16 | ms/batch 295.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  63 |     4/    9 batches | lr 0.16 | ms/batch 286.74 | loss  1.18 | ppl     3.26|\n",
      "| epoch  63 |     5/    9 batches | lr 0.16 | ms/batch 292.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  63 |     6/    9 batches | lr 0.16 | ms/batch 286.01 | loss  1.17 | ppl     3.24|\n",
      "| epoch  63 |     7/    9 batches | lr 0.16 | ms/batch 283.85 | loss  1.17 | ppl     3.23|\n",
      "| epoch  63 |     8/    9 batches | lr 0.16 | ms/batch 294.81 | loss  1.19 | ppl     3.28|\n",
      "| epoch  63 |     9/    9 batches | lr 0.16 | ms/batch 118.03 | loss  1.44 | ppl     4.22|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  3.64s | valid loss  0.91 | valid ppl     2.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |     1/    9 batches | lr 0.15 | ms/batch 567.13 | loss  2.36 | ppl    10.55|\n",
      "| epoch  64 |     2/    9 batches | lr 0.15 | ms/batch 284.06 | loss  1.17 | ppl     3.21|\n",
      "| epoch  64 |     3/    9 batches | lr 0.15 | ms/batch 287.06 | loss  1.18 | ppl     3.26|\n",
      "| epoch  64 |     4/    9 batches | lr 0.15 | ms/batch 283.06 | loss  1.18 | ppl     3.27|\n",
      "| epoch  64 |     5/    9 batches | lr 0.15 | ms/batch 284.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  64 |     6/    9 batches | lr 0.15 | ms/batch 287.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  64 |     7/    9 batches | lr 0.15 | ms/batch 283.67 | loss  1.17 | ppl     3.23|\n",
      "| epoch  64 |     8/    9 batches | lr 0.15 | ms/batch 285.12 | loss  1.16 | ppl     3.20|\n",
      "| epoch  64 |     9/    9 batches | lr 0.15 | ms/batch 120.03 | loss  1.43 | ppl     4.17|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  3.60s | valid loss  0.91 | valid ppl     2.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |     1/    9 batches | lr 0.14 | ms/batch 565.47 | loss  2.34 | ppl    10.34|\n",
      "| epoch  65 |     2/    9 batches | lr 0.14 | ms/batch 285.07 | loss  1.17 | ppl     3.23|\n",
      "| epoch  65 |     3/    9 batches | lr 0.14 | ms/batch 284.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  65 |     4/    9 batches | lr 0.14 | ms/batch 294.07 | loss  1.17 | ppl     3.23|\n",
      "| epoch  65 |     5/    9 batches | lr 0.14 | ms/batch 283.06 | loss  1.19 | ppl     3.27|\n",
      "| epoch  65 |     6/    9 batches | lr 0.14 | ms/batch 285.06 | loss  1.17 | ppl     3.24|\n",
      "| epoch  65 |     7/    9 batches | lr 0.14 | ms/batch 282.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  65 |     8/    9 batches | lr 0.14 | ms/batch 283.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  65 |     9/    9 batches | lr 0.14 | ms/batch 119.03 | loss  1.45 | ppl     4.24|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  3.59s | valid loss  0.91 | valid ppl     2.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |     1/    9 batches | lr 0.14 | ms/batch 568.13 | loss  2.34 | ppl    10.39|\n",
      "| epoch  66 |     2/    9 batches | lr 0.14 | ms/batch 283.07 | loss  1.18 | ppl     3.25|\n",
      "| epoch  66 |     3/    9 batches | lr 0.14 | ms/batch 283.06 | loss  1.18 | ppl     3.24|\n",
      "| epoch  66 |     4/    9 batches | lr 0.14 | ms/batch 287.07 | loss  1.17 | ppl     3.24|\n",
      "| epoch  66 |     5/    9 batches | lr 0.14 | ms/batch 283.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  66 |     6/    9 batches | lr 0.14 | ms/batch 284.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  66 |     7/    9 batches | lr 0.14 | ms/batch 286.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  66 |     8/    9 batches | lr 0.14 | ms/batch 286.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  66 |     9/    9 batches | lr 0.14 | ms/batch 120.03 | loss  1.46 | ppl     4.31|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  3.59s | valid loss  0.90 | valid ppl     2.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |     1/    9 batches | lr 0.13 | ms/batch 579.13 | loss  2.34 | ppl    10.43|\n",
      "| epoch  67 |     2/    9 batches | lr 0.13 | ms/batch 283.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  67 |     3/    9 batches | lr 0.13 | ms/batch 283.06 | loss  1.17 | ppl     3.21|\n",
      "| epoch  67 |     4/    9 batches | lr 0.13 | ms/batch 283.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  67 |     5/    9 batches | lr 0.13 | ms/batch 286.06 | loss  1.17 | ppl     3.22|\n",
      "| epoch  67 |     6/    9 batches | lr 0.13 | ms/batch 296.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  67 |     7/    9 batches | lr 0.13 | ms/batch 288.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  67 |     8/    9 batches | lr 0.13 | ms/batch 285.06 | loss  1.18 | ppl     3.27|\n",
      "| epoch  67 |     9/    9 batches | lr 0.13 | ms/batch 119.03 | loss  1.44 | ppl     4.22|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  3.61s | valid loss  0.90 | valid ppl     2.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |     1/    9 batches | lr 0.12 | ms/batch 567.13 | loss  2.34 | ppl    10.34|\n",
      "| epoch  68 |     2/    9 batches | lr 0.12 | ms/batch 283.06 | loss  1.18 | ppl     3.24|\n",
      "| epoch  68 |     3/    9 batches | lr 0.12 | ms/batch 284.06 | loss  1.17 | ppl     3.22|\n",
      "| epoch  68 |     4/    9 batches | lr 0.12 | ms/batch 293.07 | loss  1.18 | ppl     3.24|\n",
      "| epoch  68 |     5/    9 batches | lr 0.12 | ms/batch 282.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  68 |     6/    9 batches | lr 0.12 | ms/batch 283.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  68 |     7/    9 batches | lr 0.12 | ms/batch 287.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  68 |     8/    9 batches | lr 0.12 | ms/batch 305.07 | loss  1.17 | ppl     3.23|\n",
      "| epoch  68 |     9/    9 batches | lr 0.12 | ms/batch 129.03 | loss  1.43 | ppl     4.16|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  3.68s | valid loss  0.90 | valid ppl     2.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |     1/    9 batches | lr 0.12 | ms/batch 576.13 | loss  2.33 | ppl    10.30|\n",
      "| epoch  69 |     2/    9 batches | lr 0.12 | ms/batch 295.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  69 |     3/    9 batches | lr 0.12 | ms/batch 294.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  69 |     4/    9 batches | lr 0.12 | ms/batch 299.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  69 |     5/    9 batches | lr 0.12 | ms/batch 298.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  69 |     6/    9 batches | lr 0.12 | ms/batch 291.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  69 |     7/    9 batches | lr 0.12 | ms/batch 301.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  69 |     8/    9 batches | lr 0.12 | ms/batch 295.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  69 |     9/    9 batches | lr 0.12 | ms/batch 120.03 | loss  1.44 | ppl     4.20|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  3.68s | valid loss  0.90 | valid ppl     2.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |     1/    9 batches | lr 0.11 | ms/batch 595.13 | loss  2.35 | ppl    10.44|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  70 |     2/    9 batches | lr 0.11 | ms/batch 291.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  70 |     3/    9 batches | lr 0.11 | ms/batch 297.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  70 |     4/    9 batches | lr 0.11 | ms/batch 296.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  70 |     5/    9 batches | lr 0.11 | ms/batch 299.61 | loss  1.16 | ppl     3.20|\n",
      "| epoch  70 |     6/    9 batches | lr 0.11 | ms/batch 299.51 | loss  1.17 | ppl     3.22|\n",
      "| epoch  70 |     7/    9 batches | lr 0.11 | ms/batch 301.59 | loss  1.16 | ppl     3.19|\n",
      "| epoch  70 |     8/    9 batches | lr 0.11 | ms/batch 300.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  70 |     9/    9 batches | lr 0.11 | ms/batch 129.03 | loss  1.42 | ppl     4.15|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  3.74s | valid loss  0.90 | valid ppl     2.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 |     1/    9 batches | lr 0.10 | ms/batch 572.14 | loss  2.34 | ppl    10.42|\n",
      "| epoch  71 |     2/    9 batches | lr 0.10 | ms/batch 290.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  71 |     3/    9 batches | lr 0.10 | ms/batch 300.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  71 |     4/    9 batches | lr 0.10 | ms/batch 289.07 | loss  1.16 | ppl     3.21|\n",
      "| epoch  71 |     5/    9 batches | lr 0.10 | ms/batch 281.06 | loss  1.17 | ppl     3.21|\n",
      "| epoch  71 |     6/    9 batches | lr 0.10 | ms/batch 291.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  71 |     7/    9 batches | lr 0.10 | ms/batch 287.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  71 |     8/    9 batches | lr 0.10 | ms/batch 296.13 | loss  1.17 | ppl     3.21|\n",
      "| epoch  71 |     9/    9 batches | lr 0.10 | ms/batch 119.38 | loss  1.45 | ppl     4.25|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  3.67s | valid loss  0.89 | valid ppl     2.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |     1/    9 batches | lr 0.10 | ms/batch 592.13 | loss  2.32 | ppl    10.15|\n",
      "| epoch  72 |     2/    9 batches | lr 0.10 | ms/batch 294.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  72 |     3/    9 batches | lr 0.10 | ms/batch 298.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  72 |     4/    9 batches | lr 0.10 | ms/batch 291.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  72 |     5/    9 batches | lr 0.10 | ms/batch 294.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  72 |     6/    9 batches | lr 0.10 | ms/batch 289.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  72 |     7/    9 batches | lr 0.10 | ms/batch 286.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  72 |     8/    9 batches | lr 0.10 | ms/batch 283.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  72 |     9/    9 batches | lr 0.10 | ms/batch 121.03 | loss  1.43 | ppl     4.19|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  3.65s | valid loss  0.89 | valid ppl     2.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |     1/    9 batches | lr 0.09 | ms/batch 594.14 | loss  2.34 | ppl    10.35|\n",
      "| epoch  73 |     2/    9 batches | lr 0.09 | ms/batch 297.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  73 |     3/    9 batches | lr 0.09 | ms/batch 288.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  73 |     4/    9 batches | lr 0.09 | ms/batch 285.77 | loss  1.18 | ppl     3.25|\n",
      "| epoch  73 |     5/    9 batches | lr 0.09 | ms/batch 295.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  73 |     6/    9 batches | lr 0.09 | ms/batch 297.08 | loss  1.15 | ppl     3.16|\n",
      "| epoch  73 |     7/    9 batches | lr 0.09 | ms/batch 285.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  73 |     8/    9 batches | lr 0.09 | ms/batch 290.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  73 |     9/    9 batches | lr 0.09 | ms/batch 126.03 | loss  1.43 | ppl     4.18|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  3.68s | valid loss  0.89 | valid ppl     2.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |     1/    9 batches | lr 0.09 | ms/batch 568.13 | loss  2.33 | ppl    10.30|\n",
      "| epoch  74 |     2/    9 batches | lr 0.09 | ms/batch 285.06 | loss  1.17 | ppl     3.22|\n",
      "| epoch  74 |     3/    9 batches | lr 0.09 | ms/batch 286.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  74 |     4/    9 batches | lr 0.09 | ms/batch 283.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  74 |     5/    9 batches | lr 0.09 | ms/batch 284.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  74 |     6/    9 batches | lr 0.09 | ms/batch 285.06 | loss  1.17 | ppl     3.23|\n",
      "| epoch  74 |     7/    9 batches | lr 0.09 | ms/batch 284.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  74 |     8/    9 batches | lr 0.09 | ms/batch 284.06 | loss  1.18 | ppl     3.25|\n",
      "| epoch  74 |     9/    9 batches | lr 0.09 | ms/batch 122.03 | loss  1.42 | ppl     4.13|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  3.59s | valid loss  0.89 | valid ppl     2.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |     1/    9 batches | lr 0.09 | ms/batch 590.13 | loss  2.32 | ppl    10.20|\n",
      "| epoch  75 |     2/    9 batches | lr 0.09 | ms/batch 295.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  75 |     3/    9 batches | lr 0.09 | ms/batch 291.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  75 |     4/    9 batches | lr 0.09 | ms/batch 288.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  75 |     5/    9 batches | lr 0.09 | ms/batch 286.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  75 |     6/    9 batches | lr 0.09 | ms/batch 296.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  75 |     7/    9 batches | lr 0.09 | ms/batch 298.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  75 |     8/    9 batches | lr 0.09 | ms/batch 297.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  75 |     9/    9 batches | lr 0.09 | ms/batch 135.03 | loss  1.40 | ppl     4.07|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  3.72s | valid loss  0.89 | valid ppl     2.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |     1/    9 batches | lr 0.08 | ms/batch 574.14 | loss  2.33 | ppl    10.28|\n",
      "| epoch  76 |     2/    9 batches | lr 0.08 | ms/batch 302.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  76 |     3/    9 batches | lr 0.08 | ms/batch 302.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  76 |     4/    9 batches | lr 0.08 | ms/batch 299.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  76 |     5/    9 batches | lr 0.08 | ms/batch 299.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  76 |     6/    9 batches | lr 0.08 | ms/batch 299.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  76 |     7/    9 batches | lr 0.08 | ms/batch 300.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  76 |     8/    9 batches | lr 0.08 | ms/batch 300.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  76 |     9/    9 batches | lr 0.08 | ms/batch 128.04 | loss  1.42 | ppl     4.12|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  3.73s | valid loss  0.89 | valid ppl     2.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |     1/    9 batches | lr 0.08 | ms/batch 603.14 | loss  2.32 | ppl    10.14|\n",
      "| epoch  77 |     2/    9 batches | lr 0.08 | ms/batch 300.08 | loss  1.16 | ppl     3.18|\n",
      "| epoch  77 |     3/    9 batches | lr 0.08 | ms/batch 300.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  77 |     4/    9 batches | lr 0.08 | ms/batch 299.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  77 |     5/    9 batches | lr 0.08 | ms/batch 297.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  77 |     6/    9 batches | lr 0.08 | ms/batch 301.08 | loss  1.16 | ppl     3.19|\n",
      "| epoch  77 |     7/    9 batches | lr 0.08 | ms/batch 299.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  77 |     8/    9 batches | lr 0.08 | ms/batch 300.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  77 |     9/    9 batches | lr 0.08 | ms/batch 127.03 | loss  1.43 | ppl     4.20|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  3.73s | valid loss  0.89 | valid ppl     2.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |     1/    9 batches | lr 0.07 | ms/batch 570.13 | loss  2.32 | ppl    10.22|\n",
      "| epoch  78 |     2/    9 batches | lr 0.07 | ms/batch 285.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  78 |     3/    9 batches | lr 0.07 | ms/batch 283.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  78 |     4/    9 batches | lr 0.07 | ms/batch 290.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  78 |     5/    9 batches | lr 0.07 | ms/batch 292.07 | loss  1.17 | ppl     3.21|\n",
      "| epoch  78 |     6/    9 batches | lr 0.07 | ms/batch 290.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  78 |     7/    9 batches | lr 0.07 | ms/batch 287.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  78 |     8/    9 batches | lr 0.07 | ms/batch 286.06 | loss  1.17 | ppl     3.21|\n",
      "| epoch  78 |     9/    9 batches | lr 0.07 | ms/batch 119.03 | loss  1.41 | ppl     4.11|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  3.60s | valid loss  0.88 | valid ppl     2.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |     1/    9 batches | lr 0.07 | ms/batch 574.13 | loss  2.31 | ppl    10.06|\n",
      "| epoch  79 |     2/    9 batches | lr 0.07 | ms/batch 296.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  79 |     3/    9 batches | lr 0.07 | ms/batch 294.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  79 |     4/    9 batches | lr 0.07 | ms/batch 287.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  79 |     5/    9 batches | lr 0.07 | ms/batch 289.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  79 |     6/    9 batches | lr 0.07 | ms/batch 296.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  79 |     7/    9 batches | lr 0.07 | ms/batch 297.07 | loss  1.16 | ppl     3.17|\n",
      "| epoch  79 |     8/    9 batches | lr 0.07 | ms/batch 295.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  79 |     9/    9 batches | lr 0.07 | ms/batch 130.03 | loss  1.43 | ppl     4.17|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  3.72s | valid loss  0.88 | valid ppl     2.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |     1/    9 batches | lr 0.07 | ms/batch 599.13 | loss  2.32 | ppl    10.13|\n",
      "| epoch  80 |     2/    9 batches | lr 0.07 | ms/batch 299.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  80 |     3/    9 batches | lr 0.07 | ms/batch 300.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  80 |     4/    9 batches | lr 0.07 | ms/batch 300.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  80 |     5/    9 batches | lr 0.07 | ms/batch 300.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  80 |     6/    9 batches | lr 0.07 | ms/batch 300.07 | loss  1.17 | ppl     3.22|\n",
      "| epoch  80 |     7/    9 batches | lr 0.07 | ms/batch 298.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  80 |     8/    9 batches | lr 0.07 | ms/batch 301.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  80 |     9/    9 batches | lr 0.07 | ms/batch 131.04 | loss  1.45 | ppl     4.25|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  3.77s | valid loss  0.88 | valid ppl     2.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 |     1/    9 batches | lr 0.06 | ms/batch 594.14 | loss  2.31 | ppl    10.12|\n",
      "| epoch  81 |     2/    9 batches | lr 0.06 | ms/batch 284.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  81 |     3/    9 batches | lr 0.06 | ms/batch 282.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  81 |     4/    9 batches | lr 0.06 | ms/batch 288.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  81 |     5/    9 batches | lr 0.06 | ms/batch 289.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch  81 |     6/    9 batches | lr 0.06 | ms/batch 293.09 | loss  1.16 | ppl     3.19|\n",
      "| epoch  81 |     7/    9 batches | lr 0.06 | ms/batch 290.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  81 |     8/    9 batches | lr 0.06 | ms/batch 290.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  81 |     9/    9 batches | lr 0.06 | ms/batch 122.03 | loss  1.43 | ppl     4.19|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  3.65s | valid loss  0.88 | valid ppl     2.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |     1/    9 batches | lr 0.06 | ms/batch 588.14 | loss  2.32 | ppl    10.14|\n",
      "| epoch  82 |     2/    9 batches | lr 0.06 | ms/batch 297.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  82 |     3/    9 batches | lr 0.06 | ms/batch 290.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  82 |     4/    9 batches | lr 0.06 | ms/batch 288.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  82 |     5/    9 batches | lr 0.06 | ms/batch 294.07 | loss  1.15 | ppl     3.14|\n",
      "| epoch  82 |     6/    9 batches | lr 0.06 | ms/batch 290.08 | loss  1.15 | ppl     3.16|\n",
      "| epoch  82 |     7/    9 batches | lr 0.06 | ms/batch 295.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  82 |     8/    9 batches | lr 0.06 | ms/batch 290.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  82 |     9/    9 batches | lr 0.06 | ms/batch 128.02 | loss  1.40 | ppl     4.05|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  3.68s | valid loss  0.88 | valid ppl     2.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |     1/    9 batches | lr 0.06 | ms/batch 581.14 | loss  2.32 | ppl    10.15|\n",
      "| epoch  83 |     2/    9 batches | lr 0.06 | ms/batch 296.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  83 |     3/    9 batches | lr 0.06 | ms/batch 294.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  83 |     4/    9 batches | lr 0.06 | ms/batch 293.07 | loss  1.16 | ppl     3.17|\n",
      "| epoch  83 |     5/    9 batches | lr 0.06 | ms/batch 284.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  83 |     6/    9 batches | lr 0.06 | ms/batch 283.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch  83 |     7/    9 batches | lr 0.06 | ms/batch 281.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  83 |     8/    9 batches | lr 0.06 | ms/batch 288.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  83 |     9/    9 batches | lr 0.06 | ms/batch 122.03 | loss  1.43 | ppl     4.18|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  3.64s | valid loss  0.88 | valid ppl     2.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |     1/    9 batches | lr 0.05 | ms/batch 575.13 | loss  2.31 | ppl    10.11|\n",
      "| epoch  84 |     2/    9 batches | lr 0.05 | ms/batch 288.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch  84 |     3/    9 batches | lr 0.05 | ms/batch 286.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  84 |     4/    9 batches | lr 0.05 | ms/batch 283.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  84 |     5/    9 batches | lr 0.05 | ms/batch 281.80 | loss  1.15 | ppl     3.15|\n",
      "| epoch  84 |     6/    9 batches | lr 0.05 | ms/batch 284.06 | loss  1.16 | ppl     3.20|\n",
      "| epoch  84 |     7/    9 batches | lr 0.05 | ms/batch 286.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  84 |     8/    9 batches | lr 0.05 | ms/batch 285.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  84 |     9/    9 batches | lr 0.05 | ms/batch 126.03 | loss  1.41 | ppl     4.08|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  3.62s | valid loss  0.88 | valid ppl     2.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |     1/    9 batches | lr 0.05 | ms/batch 583.13 | loss  2.29 | ppl     9.89|\n",
      "| epoch  85 |     2/    9 batches | lr 0.05 | ms/batch 292.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  85 |     3/    9 batches | lr 0.05 | ms/batch 287.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  85 |     4/    9 batches | lr 0.05 | ms/batch 285.06 | loss  1.14 | ppl     3.13|\n",
      "| epoch  85 |     5/    9 batches | lr 0.05 | ms/batch 299.07 | loss  1.15 | ppl     3.17|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  85 |     6/    9 batches | lr 0.05 | ms/batch 297.07 | loss  1.14 | ppl     3.14|\n",
      "| epoch  85 |     7/    9 batches | lr 0.05 | ms/batch 306.18 | loss  1.15 | ppl     3.16|\n",
      "| epoch  85 |     8/    9 batches | lr 0.05 | ms/batch 304.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  85 |     9/    9 batches | lr 0.05 | ms/batch 126.03 | loss  1.42 | ppl     4.13|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  3.74s | valid loss  0.88 | valid ppl     2.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |     1/    9 batches | lr 0.05 | ms/batch 599.87 | loss  2.30 | ppl     9.99|\n",
      "| epoch  86 |     2/    9 batches | lr 0.05 | ms/batch 297.99 | loss  1.14 | ppl     3.14|\n",
      "| epoch  86 |     3/    9 batches | lr 0.05 | ms/batch 299.22 | loss  1.15 | ppl     3.17|\n",
      "| epoch  86 |     4/    9 batches | lr 0.05 | ms/batch 299.97 | loss  1.15 | ppl     3.16|\n",
      "| epoch  86 |     5/    9 batches | lr 0.05 | ms/batch 299.00 | loss  1.15 | ppl     3.17|\n",
      "| epoch  86 |     6/    9 batches | lr 0.05 | ms/batch 299.45 | loss  1.15 | ppl     3.17|\n",
      "| epoch  86 |     7/    9 batches | lr 0.05 | ms/batch 299.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  86 |     8/    9 batches | lr 0.05 | ms/batch 298.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  86 |     9/    9 batches | lr 0.05 | ms/batch 126.03 | loss  1.41 | ppl     4.12|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  3.78s | valid loss  0.88 | valid ppl     2.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |     1/    9 batches | lr 0.05 | ms/batch 600.14 | loss  2.31 | ppl    10.11|\n",
      "| epoch  87 |     2/    9 batches | lr 0.05 | ms/batch 299.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  87 |     3/    9 batches | lr 0.05 | ms/batch 298.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  87 |     4/    9 batches | lr 0.05 | ms/batch 299.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  87 |     5/    9 batches | lr 0.05 | ms/batch 297.07 | loss  1.16 | ppl     3.20|\n",
      "| epoch  87 |     6/    9 batches | lr 0.05 | ms/batch 299.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  87 |     7/    9 batches | lr 0.05 | ms/batch 301.07 | loss  1.16 | ppl     3.17|\n",
      "| epoch  87 |     8/    9 batches | lr 0.05 | ms/batch 298.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  87 |     9/    9 batches | lr 0.05 | ms/batch 127.03 | loss  1.42 | ppl     4.15|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  3.78s | valid loss  0.88 | valid ppl     2.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |     1/    9 batches | lr 0.04 | ms/batch 598.14 | loss  2.30 | ppl     9.96|\n",
      "| epoch  88 |     2/    9 batches | lr 0.04 | ms/batch 298.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  88 |     3/    9 batches | lr 0.04 | ms/batch 306.07 | loss  1.16 | ppl     3.17|\n",
      "| epoch  88 |     4/    9 batches | lr 0.04 | ms/batch 300.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  88 |     5/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  88 |     6/    9 batches | lr 0.04 | ms/batch 298.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  88 |     7/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.14 | ppl     3.13|\n",
      "| epoch  88 |     8/    9 batches | lr 0.04 | ms/batch 298.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  88 |     9/    9 batches | lr 0.04 | ms/batch 127.03 | loss  1.42 | ppl     4.12|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  3.78s | valid loss  0.87 | valid ppl     2.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |     1/    9 batches | lr 0.04 | ms/batch 601.14 | loss  2.29 | ppl     9.91|\n",
      "| epoch  89 |     2/    9 batches | lr 0.04 | ms/batch 301.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  89 |     3/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  89 |     4/    9 batches | lr 0.04 | ms/batch 300.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  89 |     5/    9 batches | lr 0.04 | ms/batch 299.08 | loss  1.16 | ppl     3.17|\n",
      "| epoch  89 |     6/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.16 | ppl     3.19|\n",
      "| epoch  89 |     7/    9 batches | lr 0.04 | ms/batch 300.07 | loss  1.14 | ppl     3.12|\n",
      "| epoch  89 |     8/    9 batches | lr 0.04 | ms/batch 298.08 | loss  1.15 | ppl     3.16|\n",
      "| epoch  89 |     9/    9 batches | lr 0.04 | ms/batch 126.02 | loss  1.41 | ppl     4.10|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  3.77s | valid loss  0.87 | valid ppl     2.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |     1/    9 batches | lr 0.04 | ms/batch 598.14 | loss  2.30 | ppl     9.98|\n",
      "| epoch  90 |     2/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  90 |     3/    9 batches | lr 0.04 | ms/batch 300.08 | loss  1.14 | ppl     3.14|\n",
      "| epoch  90 |     4/    9 batches | lr 0.04 | ms/batch 302.06 | loss  1.16 | ppl     3.19|\n",
      "| epoch  90 |     5/    9 batches | lr 0.04 | ms/batch 299.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  90 |     6/    9 batches | lr 0.04 | ms/batch 298.07 | loss  1.15 | ppl     3.14|\n",
      "| epoch  90 |     7/    9 batches | lr 0.04 | ms/batch 297.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  90 |     8/    9 batches | lr 0.04 | ms/batch 295.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  90 |     9/    9 batches | lr 0.04 | ms/batch 126.03 | loss  1.41 | ppl     4.11|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  3.76s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  91 |     1/    9 batches | lr 0.04 | ms/batch 591.13 | loss  2.30 | ppl     9.94|\n",
      "| epoch  91 |     2/    9 batches | lr 0.04 | ms/batch 296.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  91 |     3/    9 batches | lr 0.04 | ms/batch 295.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  91 |     4/    9 batches | lr 0.04 | ms/batch 293.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  91 |     5/    9 batches | lr 0.04 | ms/batch 296.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  91 |     6/    9 batches | lr 0.04 | ms/batch 292.70 | loss  1.16 | ppl     3.18|\n",
      "| epoch  91 |     7/    9 batches | lr 0.04 | ms/batch 294.60 | loss  1.15 | ppl     3.16|\n",
      "| epoch  91 |     8/    9 batches | lr 0.04 | ms/batch 294.66 | loss  1.15 | ppl     3.17|\n",
      "| epoch  91 |     9/    9 batches | lr 0.04 | ms/batch 126.03 | loss  1.41 | ppl     4.09|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  3.73s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |     1/    9 batches | lr 0.04 | ms/batch 586.13 | loss  2.29 | ppl     9.88|\n",
      "| epoch  92 |     2/    9 batches | lr 0.04 | ms/batch 282.06 | loss  1.14 | ppl     3.13|\n",
      "| epoch  92 |     3/    9 batches | lr 0.04 | ms/batch 285.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  92 |     4/    9 batches | lr 0.04 | ms/batch 293.07 | loss  1.14 | ppl     3.14|\n",
      "| epoch  92 |     5/    9 batches | lr 0.04 | ms/batch 282.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  92 |     6/    9 batches | lr 0.04 | ms/batch 281.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  92 |     7/    9 batches | lr 0.04 | ms/batch 284.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  92 |     8/    9 batches | lr 0.04 | ms/batch 286.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  92 |     9/    9 batches | lr 0.04 | ms/batch 128.03 | loss  1.39 | ppl     4.03|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  3.66s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |     1/    9 batches | lr 0.03 | ms/batch 601.14 | loss  2.28 | ppl     9.82|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  93 |     2/    9 batches | lr 0.03 | ms/batch 300.07 | loss  1.14 | ppl     3.12|\n",
      "| epoch  93 |     3/    9 batches | lr 0.03 | ms/batch 300.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  93 |     4/    9 batches | lr 0.03 | ms/batch 298.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  93 |     5/    9 batches | lr 0.03 | ms/batch 299.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  93 |     6/    9 batches | lr 0.03 | ms/batch 300.07 | loss  1.15 | ppl     3.14|\n",
      "| epoch  93 |     7/    9 batches | lr 0.03 | ms/batch 300.07 | loss  1.14 | ppl     3.13|\n",
      "| epoch  93 |     8/    9 batches | lr 0.03 | ms/batch 302.07 | loss  1.15 | ppl     3.16|\n",
      "| epoch  93 |     9/    9 batches | lr 0.03 | ms/batch 128.03 | loss  1.43 | ppl     4.16|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  3.79s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |     1/    9 batches | lr 0.03 | ms/batch 594.14 | loss  2.29 | ppl     9.83|\n",
      "| epoch  94 |     2/    9 batches | lr 0.03 | ms/batch 293.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  94 |     3/    9 batches | lr 0.03 | ms/batch 281.06 | loss  1.15 | ppl     3.14|\n",
      "| epoch  94 |     4/    9 batches | lr 0.03 | ms/batch 281.06 | loss  1.14 | ppl     3.14|\n",
      "| epoch  94 |     5/    9 batches | lr 0.03 | ms/batch 286.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  94 |     6/    9 batches | lr 0.03 | ms/batch 299.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  94 |     7/    9 batches | lr 0.03 | ms/batch 283.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  94 |     8/    9 batches | lr 0.03 | ms/batch 283.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  94 |     9/    9 batches | lr 0.03 | ms/batch 119.03 | loss  1.38 | ppl     3.99|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  3.62s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |     1/    9 batches | lr 0.03 | ms/batch 564.13 | loss  2.30 | ppl    10.00|\n",
      "| epoch  95 |     2/    9 batches | lr 0.03 | ms/batch 297.07 | loss  1.15 | ppl     3.14|\n",
      "| epoch  95 |     3/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  95 |     4/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.13 | ppl     3.11|\n",
      "| epoch  95 |     5/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch  95 |     6/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  95 |     7/    9 batches | lr 0.03 | ms/batch 296.07 | loss  1.13 | ppl     3.11|\n",
      "| epoch  95 |     8/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch  95 |     9/    9 batches | lr 0.03 | ms/batch 128.03 | loss  1.40 | ppl     4.07|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  3.60s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |     1/    9 batches | lr 0.03 | ms/batch 562.13 | loss  2.29 | ppl     9.92|\n",
      "| epoch  96 |     2/    9 batches | lr 0.03 | ms/batch 287.06 | loss  1.14 | ppl     3.13|\n",
      "| epoch  96 |     3/    9 batches | lr 0.03 | ms/batch 293.07 | loss  1.14 | ppl     3.13|\n",
      "| epoch  96 |     4/    9 batches | lr 0.03 | ms/batch 298.07 | loss  1.15 | ppl     3.17|\n",
      "| epoch  96 |     5/    9 batches | lr 0.03 | ms/batch 297.07 | loss  1.14 | ppl     3.13|\n",
      "| epoch  96 |     6/    9 batches | lr 0.03 | ms/batch 285.06 | loss  1.14 | ppl     3.14|\n",
      "| epoch  96 |     7/    9 batches | lr 0.03 | ms/batch 291.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  96 |     8/    9 batches | lr 0.03 | ms/batch 301.07 | loss  1.14 | ppl     3.14|\n",
      "| epoch  96 |     9/    9 batches | lr 0.03 | ms/batch 123.03 | loss  1.39 | ppl     4.03|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  3.66s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |     1/    9 batches | lr 0.03 | ms/batch 576.13 | loss  2.31 | ppl    10.06|\n",
      "| epoch  97 |     2/    9 batches | lr 0.03 | ms/batch 283.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  97 |     3/    9 batches | lr 0.03 | ms/batch 286.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  97 |     4/    9 batches | lr 0.03 | ms/batch 293.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  97 |     5/    9 batches | lr 0.03 | ms/batch 290.07 | loss  1.14 | ppl     3.13|\n",
      "| epoch  97 |     6/    9 batches | lr 0.03 | ms/batch 284.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  97 |     7/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.16|\n",
      "| epoch  97 |     8/    9 batches | lr 0.03 | ms/batch 286.06 | loss  1.14 | ppl     3.14|\n",
      "| epoch  97 |     9/    9 batches | lr 0.03 | ms/batch 126.03 | loss  1.40 | ppl     4.06|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  3.61s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |     1/    9 batches | lr 0.03 | ms/batch 575.66 | loss  2.29 | ppl     9.90|\n",
      "| epoch  98 |     2/    9 batches | lr 0.03 | ms/batch 280.63 | loss  1.15 | ppl     3.14|\n",
      "| epoch  98 |     3/    9 batches | lr 0.03 | ms/batch 291.66 | loss  1.15 | ppl     3.17|\n",
      "| epoch  98 |     4/    9 batches | lr 0.03 | ms/batch 291.71 | loss  1.15 | ppl     3.15|\n",
      "| epoch  98 |     5/    9 batches | lr 0.03 | ms/batch 282.07 | loss  1.14 | ppl     3.12|\n",
      "| epoch  98 |     6/    9 batches | lr 0.03 | ms/batch 283.07 | loss  1.15 | ppl     3.15|\n",
      "| epoch  98 |     7/    9 batches | lr 0.03 | ms/batch 282.94 | loss  1.15 | ppl     3.17|\n",
      "| epoch  98 |     8/    9 batches | lr 0.03 | ms/batch 282.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch  98 |     9/    9 batches | lr 0.03 | ms/batch 118.03 | loss  1.40 | ppl     4.05|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  3.58s | valid loss  0.87 | valid ppl     2.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |     1/    9 batches | lr 0.02 | ms/batch 589.04 | loss  2.30 | ppl     9.96|\n",
      "| epoch  99 |     2/    9 batches | lr 0.02 | ms/batch 300.02 | loss  1.15 | ppl     3.16|\n",
      "| epoch  99 |     3/    9 batches | lr 0.02 | ms/batch 285.02 | loss  1.16 | ppl     3.17|\n",
      "| epoch  99 |     4/    9 batches | lr 0.02 | ms/batch 281.08 | loss  1.15 | ppl     3.15|\n",
      "| epoch  99 |     5/    9 batches | lr 0.02 | ms/batch 298.07 | loss  1.16 | ppl     3.18|\n",
      "| epoch  99 |     6/    9 batches | lr 0.02 | ms/batch 293.79 | loss  1.15 | ppl     3.17|\n",
      "| epoch  99 |     7/    9 batches | lr 0.02 | ms/batch 289.06 | loss  1.16 | ppl     3.18|\n",
      "| epoch  99 |     8/    9 batches | lr 0.02 | ms/batch 290.07 | loss  1.15 | ppl     3.14|\n",
      "| epoch  99 |     9/    9 batches | lr 0.02 | ms/batch 119.02 | loss  1.42 | ppl     4.14|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  3.67s | valid loss  0.87 | valid ppl     2.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |     1/    9 batches | lr 0.02 | ms/batch 565.13 | loss  2.29 | ppl     9.85|\n",
      "| epoch 100 |     2/    9 batches | lr 0.02 | ms/batch 286.06 | loss  1.15 | ppl     3.17|\n",
      "| epoch 100 |     3/    9 batches | lr 0.02 | ms/batch 294.08 | loss  1.15 | ppl     3.15|\n",
      "| epoch 100 |     4/    9 batches | lr 0.02 | ms/batch 296.06 | loss  1.14 | ppl     3.13|\n",
      "| epoch 100 |     5/    9 batches | lr 0.02 | ms/batch 285.06 | loss  1.15 | ppl     3.15|\n",
      "| epoch 100 |     6/    9 batches | lr 0.02 | ms/batch 302.08 | loss  1.14 | ppl     3.14|\n",
      "| epoch 100 |     7/    9 batches | lr 0.02 | ms/batch 291.06 | loss  1.15 | ppl     3.14|\n",
      "| epoch 100 |     8/    9 batches | lr 0.02 | ms/batch 290.17 | loss  1.14 | ppl     3.14|\n",
      "| epoch 100 |     9/    9 batches | lr 0.02 | ms/batch 119.02 | loss  1.43 | ppl     4.18|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  3.63s | valid loss  0.87 | valid ppl     2.38\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 100 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    val_losses.append(val_loss)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XPTZdip9XkTT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDPz0G4MfyL6",
    "outputId": "b7e93030-f301-44ea-e6ba-5d917286e439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  0.87 | test ppl     2.38\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZsUG0R1oXkTT"
   },
   "outputs": [],
   "source": [
    "idx_to_letter = {val:key for key, val in char_nums.items()}\n",
    "\n",
    "def sample_categorical(lnprobs, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample an element from a categorical distribution\n",
    "    :param lnprobs: Outcome log-probabilities\n",
    "    :param temperature: Sampling temperature. 1.0 follows the given distribution,\n",
    "        0.0 returns the maximum probability element.\n",
    "    :return: The index of the sampled element.\n",
    "    \"\"\"\n",
    "\n",
    "    if temperature == 0.0:\n",
    "        return lnprobs.argmax()\n",
    "    p = F.softmax(lnprobs / temperature, dim=1)\n",
    "\n",
    "    #print(\"softmaxed probs:\", p)\n",
    "    \n",
    "    return dist.Categorical(p).sample()\n",
    "\n",
    "def sample_sentence(model, query, max_len = 140, temperature=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    while len(query) < max_len and '<eos>' not in query:\n",
    "        query_tensor, seq_lengths = batchify([query])\n",
    "        query_tensor = query_tensor.to(device)\n",
    "    \n",
    "        src_mask = model.generate_square_subsequent_mask(len(query_tensor)).to(device)\n",
    "        \n",
    "        output = model(query_tensor, src_mask, torch.Tensor([len(query)])).view(-1, ntokens)\n",
    "        \n",
    "        next_char_idx = sample_categorical(output, temperature) #0.5\n",
    "                \n",
    "        try:\n",
    "            query += [idx_to_letter[int(next_char_idx[-1])]]\n",
    "        except IndexError:\n",
    "            query += [idx_to_letter[int(next_char_idx)]]\n",
    "            \n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3rHcGmkG3_m",
    "outputId": "45ef1fc7-ae43-48ac-dc0a-f5382bd3d713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 <sos> E P T F S S S G G T A S L V Y G L V T K G G S S G T W M M Y T A M N D Q M Y T C T A S S G G L V P D T P V T P A A K <eos>\n",
      "119 <sos> E V L V T T V T G Y F T Y G L V T V D T V T V T V L V T V T V T A R D T L K K G L V T T S S G L V S N S S G Q M M Y A R Q G L Q M S S L Q T V S S G T S G S A K L V T Y F A V A M Y W V T S S S G V S G T A S Y F A G T L V G E W L V K K <eos>\n",
      "500 <sos> E G Y W G T S S G G L V T T A V K R Q M Y Y Y F P G V K N E P V T V T Y W Q M Y Y F P S G D K N N S S E P V T V K I E W T F T V T S L V T V T Q M G G G Y Y G L V T L V S Q K G G L Q M Y F T F T V S T S G V T A G L V T Y P G L V T S G S G T W Y T A K G R Q K G G R D T S V N S S L V A K S G V T S T S L Q M Y F L V T Y T V T Y W V T S G G L V T V T H T W V Q M Y W V T P S G Q M N T V T T P S D N L Q T P S G T V F T V K G Q M S L V T T S Y F P G G G S G Y F T T T T P V T L V T L V T V S L V T A V T V H I L Q M Y F S S G S S T V R D T P P G Y W L V T V T L Q P V T N S V T S L V L Q M G T A R D T F T S G G I S S G Q H I S G L Y F T W D S S G Y W L Q M Y Y Y W G T V K G L S S V D A V T V T L Q M G Y P V T L Q M Y F T V Q M G G L S L V K R Q M Y P V K K K R Q M D A K R I S S L V G G P V T V T V T T K G V A T V T A S G L Q M S S S S G L V T S S G G Q M Y Y Y W V D S T F T M D T A S Y G P G E P A S S S G S S G G L V T V E W L V S L V T L V K G A V T S S G L V Y F T L S S T N S S S G G Q T Y N\n",
      "197 <sos> E E P K K P V V T V T S T A A M Y F T Y Y G L T Q M Y W G E D T V T A R D W S G G Y F A R D S S V T I S S S G Y T I S V T I L V T V T P S L V T Q N T S Y T A K K G Y W L V K G T V T L Q M Y W Y F T F L V T S L V T S S G L V T S S T N S S L V T A G L V T C A S S G S S L V Y W Y W V K G S T L Q M N T V T V T V T T A M Y F S G V T A A K K Y F L Q M Y W G G G G L V T S S S S S T K R D S Y H <eos>\n",
      "320 <sos> E V T L Q S G T W L S G T P S Y W T V V V T A K G P P V T Y Y C A G G G A S Y W N S G G G Y W L V T S S S S Y Y F S S S E T T N S S G Y W L Q M S N Y Y F T V T L S L V T S S L V Y G G Y L V T I E E D Y N T Y F T A G Y P V T S L Q M Y A R D A G L S G G G L V L Q M Y W M Y G K R D G L V K G G L V T A T V D T A S S V T S G C K R Q T V T P T F S T P V S L Q M Y Y Y F T F S Y F T V T A K L V T S D S V T Y W L S G Y T V T A S G Y W M S S S V K P S S G L Q M Y F T L L V Y F T L S S G Y T T L V T V T V T V T G V T A K G T V P P V T V T L S T S S S T L Q M G G L Q G D F A T V T L Q M D S G Y W V T V T L S G K G G G S G I E P A S S G L K <eos>\n",
      "500 <sos> E E W S E D G V T V T V T V K K L V T A V Y W S S L V T R D S L V P A K P G T L Q K S L V T V V T P L V T I E P A K G Y F T K G V L V K P V T Y F A T A T V T S S G Y W V T P D T L V T Q M Y F T Q P S T S Y F T V T L V K R D T V T Y F P T W G G G Y T G D S L E P P V T K K K K P S S G G Y P G R Q G G T V T T L A G L V K G L Q M Y Y A A A M S V T A V K G K G Y F S E P A A K G T V Y T Y Y F S L S L V T A T V S S T T G G L V T L V T V T V D T M Y P V Y Y T V T A G L S L S L Q M D Y F T F P S S T A V T V T Y G D F L V P P L Q T F T V S S L Q G L Q M Y W L V T A R I E D S G L S G L V T A S G F T S T F S S S L V V T S G L Q M S S L V S V T S L V S S T S L V T Q M G L V S T G G M G T S G G G L V T T Q M Y W G V T S S L V K T L Q M Y Y F T M Y P A T T S G F K K S T S V T V T I E D S L V T N V D N T T T A G C A K G G T P V T S S L V T Q M Y A S S V V T F T V T P V D S S S S Y Y W V T L Q M Y T Y W L R Q P P S G N N S L V T V T T F T V D G L S V T Y G Y W V K N T L S L L V Y F T P P A A G T A K\n",
      "16 <sos> E P G G G V S L Q M G L Q K <eos>\n",
      "28 <sos> E D G L V V Y F T C K K P P P P A R D D S L V K K R <eos>\n",
      "48 <sos> E P S G S G L V T A S S E W V W F T Q M Y T P S S L K L S S C R A R Q M Y P P V T V T A V K <eos>\n",
      "251 <sos> E P P P S G S V T I L S G Y Y T S V T S T S S S S L V K R Q M S T S D S T K N S S V S G C L V T V T V T V T A S V T V V L Q Q M M S G C A M D S L V T V T P G T F T P P D L Q M Y Y Y G S V D P L V T P P D A Q K G L V A R D T S G T L V T L V T V T V K N S G V A S S S S Y F S C A S L V T N A T V T P P T T P T P K G G G G G V T L V K G T L V K R Q M Y F T P V T S S L L K L K R Q M Y P P A V T P V T F S S Y F P D S L V K R D S S S G C A S S G L V K L Q M Y Y F T V T V T Y W F T V T T I E W L V V K <eos>\n"
     ]
    }
   ],
   "source": [
    "import torch.distributions as dist\n",
    "ntokens = len(vocab)\n",
    "\n",
    "for _ in range(10):\n",
    "    sample = sample_sentence(model, [\"<sos>\",\"E\"], max_len = 500, temperature=0.9)\n",
    "\n",
    "    print(len(sample), \" \".join(sample))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvvgjJGWHhB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d0EO5DHXkTT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project2_jonas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
