{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el6WZUx3ctwE",
    "outputId": "f66a38ff-d81d-4b57-d8b2-a43989ee3151"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\\n!ls drive/'My Drive/YYY_deep_project_YYY'\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls drive/'My Drive/YYY_deep_project_YYY'\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUc-3FwsYA6X",
    "outputId": "0e1b95cc-1151-4102-ccea-a9e0edbe1f5d"
   },
   "outputs": [],
   "source": [
    "#%cd drive/'My Drive/YYY_deep_project_YYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OcYm_Z9sdVq4"
   },
   "outputs": [],
   "source": [
    "def get_sequence(infile):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        header = infile.readline()\n",
    "        sequence = infile.readline()\n",
    "\n",
    "        pdb = header[1:5]\n",
    "\n",
    "        if not header or not sequence or set(sequence) == {'X'}:\n",
    "            return\n",
    "        \n",
    "        yield header.strip()[1:], sequence.strip(), pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "mzJSiJbpXkTR",
    "outputId": "2af42cfb-ef10-4316-de19-6b89fa008527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences = []\n",
    "seq_to_pdb = {}\n",
    "count = 0\n",
    "with open('all_heavy.fasta') as infile:\n",
    "\n",
    "        for header, sequence, pdb in get_sequence(infile):\n",
    "            #if count < 500:\n",
    "            sequences.append(list(sequence))\n",
    "                #count += 1\n",
    "            \n",
    "            seq_to_pdb[sequence] = pdb\n",
    "            \n",
    "sequences = [seq for seq in sequences if len(seq) < 200]\n",
    "\n",
    "# Add the reversed sequences?\n",
    "sequences += [seq[::-1] for seq in sequences]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "mode = max(set(lengths), key=lengths.count)\n",
    "\n",
    "print(mode)\n",
    "\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lVSriKBHdqU7"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve inputs and targets at the given index\n",
    "        X = self.inputs[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "def create_datasets(sequences, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):\n",
    "    \n",
    "    \n",
    "    # Define partition sizes\n",
    "    num_train = int(len(sequences)*p_train)\n",
    "    num_val = int(len(sequences)*p_val)\n",
    "    num_test = int(len(sequences)*p_test)\n",
    "\n",
    "    # Split sequences into partitions\n",
    "    sequences_train = sequences[:num_train-1]\n",
    "    sequences_val = sequences[num_train:num_train+num_val-1]\n",
    "    sequences_test = sequences[-num_test:-1]\n",
    "\n",
    "    input_train = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_train]\n",
    "    input_val = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_val]\n",
    "    input_test = [['<sos>'] + list(seq)+['<eos>'] for seq in sequences_test]\n",
    "\n",
    "    return (input_train, input_val, input_test)\n",
    "\n",
    "(input_train, input_val, input_test) = create_datasets(sequences, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YNWaI923d3YE"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "        \n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        \n",
    "        self.t_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "        self.embed = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        \n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        \n",
    "        self.t_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "\n",
    "\n",
    "        self.ff = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float(-1e-10)).masked_fill(mask == 1, float(0.0))\n",
    "        \n",
    "        return mask\n",
    "\n",
    " \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "       \n",
    "\n",
    "    def forward(self, src, src_mask, tgt, tgt_mask, src_pad_mask, tgt_pad_mask, mem_pad_mask=None):\n",
    "        \n",
    "\n",
    "        embeds = self.embed(src) * math.sqrt(self.ninp)\n",
    "        \n",
    "        positions = self.pos_encoder(embeds)\n",
    "    \n",
    "        \n",
    "        encoded = self.t_encoder(positions)\n",
    "        #encoded = self.t_encoder(positions, src_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        \n",
    "        if mem_pad_mask is None:\n",
    "            mem_pad_mask = tgt_pad_mask.clone()\n",
    "            \n",
    "        embeds = self.embed(tgt)\n",
    "        positions = self.pos_encoder(embeds)\n",
    "        #decoded = self.t_decoder(tgt=positions, memory=encoded, tgt_mask=tgt_mask,\n",
    "        #                         tgt_key_padding_mask=tgt_pad_mask,\n",
    "        #                         memory_key_padding_mask=mem_pad_mask)\n",
    "        \n",
    "        decoded = self.t_decoder(tgt=positions, memory=encoded, tgt_mask=tgt_mask)\n",
    "  \n",
    "        output = self.ff(decoded)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBtnWGt-Al99",
    "outputId": "50cdbe94-9ab1-4a92-a5e6-5f50335a9208"
   },
   "outputs": [],
   "source": [
    "    \n",
    "vocab = ['<pad>', \"<sos>\", \"<eos>\"] + [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"X\",\"Y\"]\n",
    "char_nums = {token:vocab.index(token) for token in vocab}\n",
    "\n",
    "def batchify(data):\n",
    "    \n",
    "    # get the length of each seq in your batch\n",
    "    seq_lengths = torch.LongTensor([len(seq) for seq in data])\n",
    "\n",
    "    train_vectorized = [[char_nums[char] for char in seq] for seq in data]\n",
    "    \n",
    "    sources = [seq[:-1] for seq in train_vectorized]\n",
    "    targets = [seq[1:] for seq in train_vectorized]\n",
    "    \n",
    "    # dump padding everywhere, and place seqs on the left.\n",
    "    # NOTE: you only need a tensor as big as your longest sequence\n",
    "    src_tensor = torch.zeros((len(train_vectorized), seq_lengths.max()-1)).long()\n",
    "    tgt_tensor = torch.zeros((len(train_vectorized), seq_lengths.max()-1)).long()\n",
    "\n",
    "    \n",
    "    for idx, (seq, seqlen) in enumerate(zip(sources, seq_lengths)):\n",
    "        src_tensor[idx, :(seqlen-1)] = torch.LongTensor(seq)\n",
    "    \n",
    "    for idx, (seq, seqlen) in enumerate(zip(targets, seq_lengths)):\n",
    "        tgt_tensor[idx, :(seqlen-1)] = torch.LongTensor(seq)\n",
    "        \n",
    "        \n",
    "    # SORT YOUR TENSORS BY LENGTH!\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "    \n",
    "    src_tensor = src_tensor[perm_idx]\n",
    "    tgt_tensor = tgt_tensor[perm_idx]\n",
    "\n",
    "    return src_tensor, tgt_tensor\n",
    "\n",
    "\n",
    "(train_src, train_tgt) = batchify(input_train)\n",
    "(val_src, val_tgt) = batchify(input_train)\n",
    "(test_src, test_tgt) = batchify(input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UglAQA33frSw"
   },
   "outputs": [],
   "source": [
    "bptt = 60\n",
    "max_len = max(map(len, sequences))\n",
    "def get_batch(sources, targets, i):\n",
    "    n_seqs = min(bptt, len(sources) - 1 - i)\n",
    "    \n",
    "    src = torch.cat([sources[i] for i in range(n_seqs)]).view(n_seqs,max_len+1)\n",
    "        \n",
    "    target = torch.cat([targets[i] for i in range(n_seqs)]).view(n_seqs,max_len+1)#.reshape(-1)\n",
    "    \n",
    "    return src, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tLXVBEIrfr-D"
   },
   "outputs": [],
   "source": [
    "ntokens = len(vocab) # the size of vocabulary\n",
    "emsize = 800 # embedding dimension\n",
    "nhid = 400 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.5 # the dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Qc1m7dgifuPc"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#  ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "lr = 4.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "#optimizer  = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model.to(device)\n",
    "import sys\n",
    "import time\n",
    "def train():\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    n_batches = 0\n",
    "    \n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(vocab)\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_src.size(0) - 1, bptt)):\n",
    "        \n",
    "        data, targets = get_batch(train_src, train_tgt, i)\n",
    "    \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        src_pad_mask = (data == 0).bool().view(data.size(1), data.size(0))\n",
    "        \n",
    "        tgt_mask = model.generate_square_subsequent_mask(targets.size(0)).to(device)\n",
    "        tgt_pad_mask = (targets == 0).bool().view(targets.size(1), targets.size(0))\n",
    "        \n",
    "        output = model(data, src_mask, targets, tgt_mask, src_pad_mask, tgt_pad_mask)\n",
    "     \n",
    "        output_trans = output.view(-1, ntokens)\n",
    "        target_trans = targets.view(-1, targets.size(1) * targets.size(0)).squeeze(0)\n",
    "        \n",
    "        loss = criterion(output_trans, target_trans)\n",
    "        \n",
    "        n_batches += 1\n",
    "        train_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        \n",
    "        # Soft, hard accuracy\n",
    "        #o = list(output.view(-1, ntokens)[0])\n",
    "        #t = targets\n",
    "        #print(o,t)\n",
    "        #hard_acc = sum([i for i in range(len(targets)) if o[i] == t[i]])/len(targets)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        log_interval = 1\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}|'.format(\n",
    "                    epoch, batch, len(train_src) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "    train_losses.append(train_loss/n_batches)\n",
    "\n",
    "def evaluate(eval_model, src, tgt):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    \n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, src.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(src, tgt, i)\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            src_pad_mask = (data == 0).bool().view(data.size(1), data.size(0))\n",
    "        \n",
    "            tgt_mask = model.generate_square_subsequent_mask(targets.size(0)).to(device)\n",
    "            tgt_pad_mask = (targets == 0).bool().view(targets.size(1), targets.size(0))    \n",
    "            \n",
    "            output = eval_model(data, src_mask, targets, tgt_mask, src_pad_mask, tgt_pad_mask)\n",
    "            \n",
    "            output_trans = output.view(-1, ntokens)\n",
    "            target_trans = targets.view(-1, targets.size(1) * targets.size(0)).squeeze(0)\n",
    "            \n",
    "            total_loss += len(data) * criterion(output_trans, target_trans).item()\n",
    "            \n",
    "    return total_loss / (len(src) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "tZDramCJfwec",
    "outputId": "6b842e7f-b493-42a1-8118-c263cf475722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/    9 batches | lr 4.00 | ms/batch 75800.71 | loss 11.73 | ppl 124733.76|\n",
      "| epoch   1 |     2/    9 batches | lr 4.00 | ms/batch 38958.12 | loss  8.75 | ppl  6279.66|\n",
      "| epoch   1 |     3/    9 batches | lr 4.00 | ms/batch 39878.73 | loss  7.86 | ppl  2585.06|\n",
      "| epoch   1 |     4/    9 batches | lr 4.00 | ms/batch 37974.11 | loss  7.68 | ppl  2155.34|\n",
      "| epoch   1 |     5/    9 batches | lr 4.00 | ms/batch 37624.82 | loss 14.67 | ppl 2360867.20|\n",
      "| epoch   1 |     6/    9 batches | lr 4.00 | ms/batch 37713.76 | loss 12.46 | ppl 258877.53|\n",
      "| epoch   1 |     7/    9 batches | lr 4.00 | ms/batch 38069.89 | loss 10.48 | ppl 35573.52|\n",
      "| epoch   1 |     8/    9 batches | lr 4.00 | ms/batch 38521.61 | loss  8.77 | ppl  6456.29|\n",
      "| epoch   1 |     9/    9 batches | lr 4.00 | ms/batch 13421.02 | loss  8.92 | ppl  7512.49|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 469.26s | valid loss 18.88 | valid ppl 158006183.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     1/    9 batches | lr 3.61 | ms/batch 76991.02 | loss 21.34 | ppl 1855369309.27|\n",
      "| epoch   2 |     2/    9 batches | lr 3.61 | ms/batch 38490.84 | loss  9.58 | ppl 14462.24|\n",
      "| epoch   2 |     3/    9 batches | lr 3.61 | ms/batch 38173.82 | loss  8.65 | ppl  5715.18|\n",
      "| epoch   2 |     4/    9 batches | lr 3.61 | ms/batch 37727.79 | loss  6.60 | ppl   736.12|\n",
      "| epoch   2 |     5/    9 batches | lr 3.61 | ms/batch 37821.59 | loss  6.63 | ppl   756.45|\n",
      "| epoch   2 |     6/    9 batches | lr 3.61 | ms/batch 37766.89 | loss  8.51 | ppl  4964.48|\n",
      "| epoch   2 |     7/    9 batches | lr 3.61 | ms/batch 37673.42 | loss  7.71 | ppl  2232.22|\n",
      "| epoch   2 |     8/    9 batches | lr 3.61 | ms/batch 37746.53 | loss  8.27 | ppl  3896.03|\n",
      "| epoch   2 |     9/    9 batches | lr 3.61 | ms/batch 13417.23 | loss  6.86 | ppl   949.06|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 466.45s | valid loss 15.96 | valid ppl 8515772.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |     1/    9 batches | lr 3.43 | ms/batch 77426.09 | loss 15.96 | ppl 8569049.66|\n",
      "| epoch   3 |     2/    9 batches | lr 3.43 | ms/batch 38320.01 | loss  7.35 | ppl  1552.62|\n",
      "| epoch   3 |     3/    9 batches | lr 3.43 | ms/batch 38650.19 | loss  6.91 | ppl   998.60|\n",
      "| epoch   3 |     4/    9 batches | lr 3.43 | ms/batch 38014.26 | loss  7.41 | ppl  1656.51|\n",
      "| epoch   3 |     5/    9 batches | lr 3.43 | ms/batch 38220.96 | loss  6.04 | ppl   419.37|\n",
      "| epoch   3 |     6/    9 batches | lr 3.43 | ms/batch 38682.39 | loss  6.25 | ppl   516.75|\n",
      "| epoch   3 |     7/    9 batches | lr 3.43 | ms/batch 39543.58 | loss  5.35 | ppl   210.83|\n",
      "| epoch   3 |     8/    9 batches | lr 3.43 | ms/batch 41520.79 | loss  4.92 | ppl   137.13|\n",
      "| epoch   3 |     9/    9 batches | lr 3.43 | ms/batch 13569.79 | loss  5.54 | ppl   255.35|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 475.01s | valid loss  9.71 | valid ppl 16439.67\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_src, val_tgt)\n",
    "    val_losses.append(val_loss)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XPTZdip9XkTT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.707452886045191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.707452886045191"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_losses[-1])\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDPz0G4MfyL6",
    "outputId": "b7e93030-f301-44ea-e6ba-5d917286e439"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-de4b76e565b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n\u001b[1;32m      4\u001b[0m     test_loss, math.exp(test_loss)))\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-8ab574967eda>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(eval_model, src, tgt)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mtgt_pad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0moutput_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-ce4dbee06f0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, tgt, tgt_mask, src_pad_mask, tgt_pad_mask, mem_pad_mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m#encoded = self.t_encoder(positions, src_key_padding_mask=src_pad_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[1;32m    294\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[1;32m    977\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4146\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_src, test_tgt)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZsUG0R1oXkTT"
   },
   "outputs": [],
   "source": [
    "idx_to_letter = {val:key for key, val in char_nums.items()}\n",
    "\n",
    "def sample_categorical(lnprobs, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample an element from a categorical distribution\n",
    "    :param lnprobs: Outcome log-probabilities\n",
    "    :param temperature: Sampling temperature. 1.0 follows the given distribution,\n",
    "        0.0 returns the maximum probability element.\n",
    "    :return: The index of the sampled element.\n",
    "    \"\"\"\n",
    "\n",
    "    if temperature == 0.0:\n",
    "        return lnprobs.argmax()\n",
    "    p = F.softmax(lnprobs / temperature, dim=1)\n",
    "\n",
    "    #print(\"softmaxed probs:\", p)\n",
    "    \n",
    "    return dist.Categorical(p).sample()\n",
    "\n",
    "def sample_sentence(model, query, max_len = 140, temperature=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    while len(query) < max_len and '<eos>' not in query:\n",
    "        query_tensor, seq_lengths = batchify([query])\n",
    "        query_tensor = query_tensor.to(device)\n",
    "    \n",
    "        src_mask = model.generate_square_subsequent_mask(len(query_tensor)).to(device)\n",
    "        \n",
    "        output = model(query_tensor, src_mask, torch.Tensor([len(query)])).view(-1, ntokens)\n",
    "        \n",
    "        next_char_idx = sample_categorical(output, temperature) #0.5\n",
    "                \n",
    "        try:\n",
    "            query += [idx_to_letter[int(next_char_idx[-1])]]\n",
    "        except IndexError:\n",
    "            query += [idx_to_letter[int(next_char_idx)]]\n",
    "            \n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3rHcGmkG3_m",
    "outputId": "45ef1fc7-ae43-48ac-dc0a-f5382bd3d713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 <sos> E P T F S S S G G T A S L V Y G L V T K G G S S G T W M M Y T A M N D Q M Y T C T A S S G G L V P D T P V T P A A K <eos>\n",
      "119 <sos> E V L V T T V T G Y F T Y G L V T V D T V T V T V L V T V T V T A R D T L K K G L V T T S S G L V S N S S G Q M M Y A R Q G L Q M S S L Q T V S S G T S G S A K L V T Y F A V A M Y W V T S S S G V S G T A S Y F A G T L V G E W L V K K <eos>\n",
      "500 <sos> E G Y W G T S S G G L V T T A V K R Q M Y Y Y F P G V K N E P V T V T Y W Q M Y Y F P S G D K N N S S E P V T V K I E W T F T V T S L V T V T Q M G G G Y Y G L V T L V S Q K G G L Q M Y F T F T V S T S G V T A G L V T Y P G L V T S G S G T W Y T A K G R Q K G G R D T S V N S S L V A K S G V T S T S L Q M Y F L V T Y T V T Y W V T S G G L V T V T H T W V Q M Y W V T P S G Q M N T V T T P S D N L Q T P S G T V F T V K G Q M S L V T T S Y F P G G G S G Y F T T T T P V T L V T L V T V S L V T A V T V H I L Q M Y F S S G S S T V R D T P P G Y W L V T V T L Q P V T N S V T S L V L Q M G T A R D T F T S G G I S S G Q H I S G L Y F T W D S S G Y W L Q M Y Y Y W G T V K G L S S V D A V T V T L Q M G Y P V T L Q M Y F T V Q M G G L S L V K R Q M Y P V K K K R Q M D A K R I S S L V G G P V T V T V T T K G V A T V T A S G L Q M S S S S G L V T S S G G Q M Y Y Y W V D S T F T M D T A S Y G P G E P A S S S G S S G G L V T V E W L V S L V T L V K G A V T S S G L V Y F T L S S T N S S S G G Q T Y N\n",
      "197 <sos> E E P K K P V V T V T S T A A M Y F T Y Y G L T Q M Y W G E D T V T A R D W S G G Y F A R D S S V T I S S S G Y T I S V T I L V T V T P S L V T Q N T S Y T A K K G Y W L V K G T V T L Q M Y W Y F T F L V T S L V T S S G L V T S S T N S S L V T A G L V T C A S S G S S L V Y W Y W V K G S T L Q M N T V T V T V T T A M Y F S G V T A A K K Y F L Q M Y W G G G G L V T S S S S S T K R D S Y H <eos>\n",
      "320 <sos> E V T L Q S G T W L S G T P S Y W T V V V T A K G P P V T Y Y C A G G G A S Y W N S G G G Y W L V T S S S S Y Y F S S S E T T N S S G Y W L Q M S N Y Y F T V T L S L V T S S L V Y G G Y L V T I E E D Y N T Y F T A G Y P V T S L Q M Y A R D A G L S G G G L V L Q M Y W M Y G K R D G L V K G G L V T A T V D T A S S V T S G C K R Q T V T P T F S T P V S L Q M Y Y Y F T F S Y F T V T A K L V T S D S V T Y W L S G Y T V T A S G Y W M S S S V K P S S G L Q M Y F T L L V Y F T L S S G Y T T L V T V T V T V T G V T A K G T V P P V T V T L S T S S S T L Q M G G L Q G D F A T V T L Q M D S G Y W V T V T L S G K G G G S G I E P A S S G L K <eos>\n",
      "500 <sos> E E W S E D G V T V T V T V K K L V T A V Y W S S L V T R D S L V P A K P G T L Q K S L V T V V T P L V T I E P A K G Y F T K G V L V K P V T Y F A T A T V T S S G Y W V T P D T L V T Q M Y F T Q P S T S Y F T V T L V K R D T V T Y F P T W G G G Y T G D S L E P P V T K K K K P S S G G Y P G R Q G G T V T T L A G L V K G L Q M Y Y A A A M S V T A V K G K G Y F S E P A A K G T V Y T Y Y F S L S L V T A T V S S T T G G L V T L V T V T V D T M Y P V Y Y T V T A G L S L S L Q M D Y F T F P S S T A V T V T Y G D F L V P P L Q T F T V S S L Q G L Q M Y W L V T A R I E D S G L S G L V T A S G F T S T F S S S L V V T S G L Q M S S L V S V T S L V S S T S L V T Q M G L V S T G G M G T S G G G L V T T Q M Y W G V T S S L V K T L Q M Y Y F T M Y P A T T S G F K K S T S V T V T I E D S L V T N V D N T T T A G C A K G G T P V T S S L V T Q M Y A S S V V T F T V T P V D S S S S Y Y W V T L Q M Y T Y W L R Q P P S G N N S L V T V T T F T V D G L S V T Y G Y W V K N T L S L L V Y F T P P A A G T A K\n",
      "16 <sos> E P G G G V S L Q M G L Q K <eos>\n",
      "28 <sos> E D G L V V Y F T C K K P P P P A R D D S L V K K R <eos>\n",
      "48 <sos> E P S G S G L V T A S S E W V W F T Q M Y T P S S L K L S S C R A R Q M Y P P V T V T A V K <eos>\n",
      "251 <sos> E P P P S G S V T I L S G Y Y T S V T S T S S S S L V K R Q M S T S D S T K N S S V S G C L V T V T V T V T A S V T V V L Q Q M M S G C A M D S L V T V T P G T F T P P D L Q M Y Y Y G S V D P L V T P P D A Q K G L V A R D T S G T L V T L V T V T V K N S G V A S S S S Y F S C A S L V T N A T V T P P T T P T P K G G G G G V T L V K G T L V K R Q M Y F T P V T S S L L K L K R Q M Y P P A V T P V T F S S Y F P D S L V K R D S S S G C A S S G L V K L Q M Y Y F T V T V T Y W F T V T T I E W L V V K <eos>\n"
     ]
    }
   ],
   "source": [
    "import torch.distributions as dist\n",
    "ntokens = len(vocab)\n",
    "\n",
    "for _ in range(10):\n",
    "    sample = sample_sentence(model, [\"<sos>\",\"E\"], max_len = 500, temperature=0.9)\n",
    "\n",
    "    print(len(sample), \" \".join(sample))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvvgjJGWHhB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d0EO5DHXkTT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project2_jonas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
